<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research Notes</title>
    <description></description>
    <link>http://localhost:4000/researchNotes/</link>
    <atom:link href="http://localhost:4000/researchNotes/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 22 May 2017 19:08:31 -0400</pubDate>
    <lastBuildDate>Mon, 22 May 2017 19:08:31 -0400</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title> M-estimator affect on covariance  </title>
        <description>&lt;p&gt;Now that we have several robust optimization techniques implemented, which clearly have a benefit in the positioning domain when compared to $L_2$, we would like to see how these techniques affect the uncertainty in the estimated state. To evaluate this, a simple test case was constructed where only odometery measurements and loop-closure constraints were added to the pose graph. The test graph can be seen below.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/odometryTestCorrect_zpsalpe0u7s.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/odometryTestCorrect_zpsalpe0u7s.png&quot; border=&quot;0&quot; alt=&quot;correctOdo photo odometryTestCorrect_zpsalpe0u7s.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Simple odometry test case 
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With this simple test case, both $L_2$ and Huber optimization were tested. First, the graph was optimized using the $L_2$ cost function. The optimized graph and covariance of each node can be seen in the figure below.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/noFalseConstraint_zpsnepnrnte.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/noFalseConstraint_zpsnepnrnte.png&quot; border=&quot;0&quot; alt=&quot;noFalseConstraintL2 photo noFalseConstraint_zpsnepnrnte.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
$L_2$ optimization with no false constraints 
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Next, the Huber robust noise model was utilized. Again, the optimized graph and associated covariance of each node can be seen in the figure below. As would be expected, there is no substantial difference between the optimized solutions.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/noFalseConstraintHuber_zpsxg0lnur1.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/noFalseConstraintHuber_zpsxg0lnur1.png&quot; border=&quot;0&quot; alt=&quot;NoFalseConstaintHuber photo noFalseConstraintHuber_zpsxg0lnur1.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Huber optimization with no false constraints 
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now, a false loop-closure constraint is added between nodes two and four — the optimizer believes that these nodes should be zero meters apart with an uncertainty of 0.2 meters on position. The new initial pose graph is depicted below.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/odometryTestCorrect_zpsgtdn0vsr.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/odometryTestCorrect_zpsgtdn0vsr.png&quot; border=&quot;0&quot; alt=&quot;incorrectOdo photo odometryTestCorrect_zpsgtdn0vsr.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Odometry test case with one false loop-closure 
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Using the pose graph with a false loop-closure constraint as depicted above, $L_2$ optimization is performed again. When processing a graph that containts faults, it can clearly be seen in the figure below that the position solution is skewed by the false constraint; however, this does not correspond to a substantially larger uncertainty in the estimated state.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/falseConstraintNonRobust_zpsfbfunf04.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/falseConstraintNonRobust_zpsfbfunf04.png&quot; border=&quot;0&quot; alt=&quot;falseConstNonRobust photo falseConstraintNonRobust_zpsfbfunf04.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
$L_2$ optimization with false constraint
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Optimizing the same graph with the Huber noise model shows substancial imporvement with respect to positioning accuracy when compared to $L_2$ optimization. Additionally, the uncertainty in the state is increase, which is desired.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/falseConstraintHuber_zpspzt0omjk.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/falseConstraintHuber_zpspzt0omjk.png&quot; border=&quot;0&quot; alt=&quot;falseConstraintHuber photo falseConstraintHuber_zpspzt0omjk.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Huber optimization with false constraint
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;these-results-will-be-validated-tomorrow-with-more-robust-noise-models-being-tested&quot;&gt;These results will be validated tomorrow with more robust noise models being tested.&lt;/h3&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 22 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/summerafit/2017/05/22/Update.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/summerafit/2017/05/22/Update.html</guid>
        
        <category>summerAFIT</category>
        
        <category>covariance</category>
        
        <category>m-estimator</category>
        
        
        <category>_projects</category>
        
        <category>summerAFIT</category>
        
      </item>
    
      <item>
        <title> Continue Testing DCS and SF </title>
        <description>&lt;h3 id=&quot;city-1000&quot;&gt;City 1000&lt;/h3&gt;
&lt;p&gt;The first dataset that we will look at is the commonly used city10000. This is a simulated dataset, which was original pose graph can be seen below.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/city10000_zps0oc5nogs.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/city10000_zps0oc5nogs.png&quot; border=&quot;0&quot; alt=&quot;city10000 photo city10000_zps0oc5nogs.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Pose Graph for City 10,000
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Interestingly, the Levenberg–Marquardt least-squares would not work on this specific dataset. So, for this dataset, the Gauss–Newton implementation was used. A side-by-side comparison of the L-M and G-N algorithms attempting to optimize the city10000 graph is shown below ( Gauss-Newton implementation is shown on the right ).&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/JdV3OS8evgU&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Using the initial error free pose graph shown above, multiple false constraints were added to evaluate the performance of the robust optimization scheme. As a reference, the results for traditional $L^2$ optimization when 10 false constraints are present is $\mathcal{X}^2$ = 21634.
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/city10000Comp_zpsh2vu19tw.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/city10000Comp_zpsh2vu19tw.png&quot; border=&quot;0&quot; alt=&quot;city10000Comp photo city10000Comp_zpsh2vu19tw.png&quot; /&gt;&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;csail&quot;&gt;CSAIL&lt;/h3&gt;

&lt;p&gt;This dataset is built from raw data acquired at the MIT CSAIL building (the relative pose measurements are also available &lt;a href=&quot;http://ais.informatik.uni-freiburg.de/slamevaluation&quot;&gt;here&lt;/a&gt; )&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.lucacarlone.com/images/csail.jpg&quot; alt=&quot;man10000&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Inital Pose Graph for CSAIL
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Again, using the initial error free pose graph shown above, multiple false constraints were added to evaluate the performance of the robust optimization scheme. The results for DCS and switch factors are shown below.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/csailComp_zpssqvk4aug.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/csailComp_zpssqvk4aug.png&quot; border=&quot;0&quot; alt=&quot;csailComp.png photo csailComp_zpssqvk4aug.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;freiburg-building&quot;&gt;Freiburg Building&lt;/h3&gt;

&lt;p&gt;This pose graph is generated from raw data acquired at the Freiburg Building (the relative pose measurements are also available &lt;a href=&quot;http://ais.informatik.uni-freiburg.de/slamevaluation&quot;&gt;here&lt;/a&gt; )&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.lucacarlone.com/images/fr079.jpg&quot; alt=&quot;man10000&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Inital Pose Graph for FR079
&lt;/p&gt;

&lt;p&gt;Faults were added to the fault free graph in the same manner as state before. The results for DCS and switch factors are shown below.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/fr079Comp_zpsgno9zeok.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/fr079Comp_zpsgno9zeok.png&quot; border=&quot;0&quot; alt=&quot;fr079Comp photo fr079Comp_zpsgno9zeok.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;freiburg-clinic&quot;&gt;Freiburg Clinic&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://www.lucacarlone.com/images/frClinic.jpg&quot; alt=&quot;man10000&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Inital Pose Graph for Freiburg Clinic
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;next-im-going-to-move-to-max-mix-model&quot;&gt;Next, I’m going to move to Max-Mix model&lt;/h3&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 19 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/summerafit/2017/05/19/Update.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/summerafit/2017/05/19/Update.html</guid>
        
        <category>summerAFIT</category>
        
        <category>dcs</category>
        
        <category>switchable constraint</category>
        
        
        <category>_projects</category>
        
        <category>summerAFIT</category>
        
      </item>
    
      <item>
        <title> DCS Vs. SF &amp; Inital Testing of RRR </title>
        <description>&lt;h2 id=&quot;realizing-reversing-recovering&quot;&gt;Realizing, Reversing, Recovering&lt;/h2&gt;

&lt;h3 id=&quot;good-description&quot;&gt;Good description&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;RRR divides
loop closures into clusters based on topological similarity and then tries to find the largest subset of clusters than are consistent among themselves as well as with the underlying odometry. Consistency is considered in the chi-squared ($\mathcal{X}^2)$ sense. The algorithm first carries out consistency checks for each cluster in order to weed out incorrect links within it, followed by an intra-cluster consistency check. RRR is different from the previous algorithms as it explicitly requires convergence of the graph in order to verify the validity of loop closures. In contrast with SC and DCS, in RRR and MM loop closure decisions are not modeled as continuous variables but as discrete yes/no decisions that need to be made&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;REF&lt;/em&gt; $\rightarrow$ &lt;a href=&quot;http://n.ethz.ch/~cesarc/files/IROS2014_latif.pdf&quot;&gt;this paper&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;getting-rrr-to-run-on-ubuntu-1604&quot;&gt;Getting RRR to run on Ubuntu 16.04&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git clone https://github.com/ylatif/rrr.git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;rrr
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;mkdir build; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;build;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;G2O_INCLUDE_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'~/Documents/git/g2o/g2o/core'&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;G2O_LIBRARIES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'~/Documents/git/g2o/lib'&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;EDITOR CMakeLists.txt

copy the following line into CMakeLists.txt so that gcc knows to 
compile the library with c++11. 


&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;CMAKE_CXX_FLAGS &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CMAKE_CXX_FLAGS&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; -std=c++11&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;cmake ../; make

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;inital-test&quot;&gt;Inital Test&lt;/h3&gt;

&lt;p&gt;To perform an initial test of RRR, the Manhattan 3500 dataset with 10 false constraints was used. The image below shows the optimized pose graph using RRR. These results are not great ( $\mathcal{X}^2$ = 1539.7 ); however, it does show improvement over $L^2$, which has a total graph error of $\mathcal{X}^2$ = 3494.7&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/Screenshot%20from%202017-05-18%2016-40-41_zpsqb6a3lyw.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/Screenshot%20from%202017-05-18%2016-40-41_zpsqb6a3lyw.png&quot; border=&quot;0&quot; alt=&quot;rrrInitialTest photo Screenshot from 2017-05-18 16-40-41_zpsqb6a3lyw.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;switch-factors-vs-dcs&quot;&gt;Switch Factors Vs. DCS&lt;/h2&gt;

&lt;p&gt;This section provides a performance evaluation of Switchable constraints and DCS when faced with a faulty initial graph. To do this, four commonly used datasets were selected and false loop closure constraints were added. Using these faulty datasets we quantify performance by looking at total graph error ( $\mathcal{X}^2$ ) and the number of iterations required to reach the minimum.&lt;/p&gt;

&lt;h3 id=&quot;manhattan-3500&quot;&gt;Manhattan 3500&lt;/h3&gt;

&lt;p&gt;The first dataset that we will look at is the commonly used Manhattan 3500. This is a simulated dataset, which was originally developed by Olson for &lt;a href=&quot;http://rvsn.csail.mit.edu/graphoptim/eolson-graphoptim2006.pdf&quot;&gt;this paper&lt;/a&gt;. A picture of the initial pose graph is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.lucacarlone.com/images/M3500_eg2o.jpg&quot; alt=&quot;man3500&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Pose Graph for Manhattan
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Using the initial error free pose graph shown above, multiple false constraints were added to evaluate the performance of the robust optimization scheme. As a reference, the results for traditional $L^2$ optimization is shown below. ( Note, to reduce the amount of time to conduct this study, I limited the maximum number of iterations to 1000 )
&lt;br /&gt;&lt;/p&gt;

&lt;table class=&quot;mbtablestyle&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Num. False Constraints&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Num. Iterations&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$\mathcal{X}^2$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;110&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3494.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6519.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;30&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9776.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12736.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;50&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;13998.3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The image below shows the optimization results for DCS and switch factors. Obviously, this is quite a dramatic improvement when compared to $L^2$ optimization.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/m3500Comp_zpsspuzzjkx.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/m3500Comp_zpsspuzzjkx.png&quot; border=&quot;0&quot; alt=&quot;m3500Comp photo m3500Comp_zpsspuzzjkx.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Optimization results for Manhattan 3500
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;intel&quot;&gt;Intel&lt;/h3&gt;

&lt;p&gt;The next dataset we will look at was collected at Intel Reseach Lab in Seattle. This pose graph was obtained by processing the raw measurements from wheel odometry and laser range finder. The raw data can be found &lt;a href=&quot;http://ais.informatik.uni-freiburg.de/slamevaluation&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;http://www.lucacarlone.com/images/intel_lago_map.jpg&quot; alt=&quot;sphere3500&quot; align=&quot;middle&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Inital Pose Graph for Sphere 3500
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Again, using the initial error free pose graph shown above, multiple false constraints were added to evaluate the performance of the robust optimization scheme. The results for DCS and switch factors are shown below. To provide scale, the total graph error for $L^2$ optimization when there are 10 false constraints is $\mathcal{X}^2$ = 8076.2.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/intelComp_zpsod0k5ac6.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/intelComp_zpsod0k5ac6.png&quot; border=&quot;0&quot; alt=&quot;intelComp photo intelComp_zpsod0k5ac6.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Optimization results for Intel 
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 18 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/summerafit/2017/05/18/Update.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/summerafit/2017/05/18/Update.html</guid>
        
        <category>summerAFIT</category>
        
        <category>rrr</category>
        
        <category>dcs</category>
        
        <category>switchable constraint</category>
        
        
        <category>_projects</category>
        
        <category>summerAFIT</category>
        
      </item>
    
      <item>
        <title> Testing Robust Noise Models --- Continued </title>
        <description>&lt;h1 id=&quot;robust-noise-models&quot;&gt;Robust Noise Models&lt;/h1&gt;

&lt;h2 id=&quot;m-estimators&quot;&gt;M-Estimators&lt;/h2&gt;
&lt;h4 id=&quot;comparing-kernel-width&quot;&gt;Comparing kernel width&lt;/h4&gt;

&lt;p&gt;For all comparisons provided yesterday, the kernel width for all m-estimators was fixed at 10. To see how the kernel width affects both the final solution accuracy and convergence time, a comparison was conducted where the only varied parameter was the Cauchy kernel width.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/CrMQd4Jgovw&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The number of iterations required before L.M. reached a stop criterion and final graph error is shown in the table below.&lt;/p&gt;

&lt;table class=&quot;mbtablestyle&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Kernel Width&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Num. Iterations&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$\mathcal{X}^2$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;K = 1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;149&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1677.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;K = 5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;460&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2608.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;K = 10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;136&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3664.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;K = 15&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1462&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5081.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
So, it’s obvious that the kernel width can dramatically affect both the solution accuracy and convergence time. At some point in the future I will run a similar study with all m-estimators.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;robust-graphical-methods&quot;&gt;Robust Graphical Methods&lt;/h2&gt;

&lt;p&gt;Now, I’m going to move from testing traditional m-estimator weighting schemes to more recent weight schemes developed specifically for navigation applications. These methods include &lt;a href=&quot;https://www.tu-chemnitz.de/etit/proaut/mitarbeiter/rsrc/IROS12-switchableConstraints.pdf&quot;&gt;switchable constraints&lt;/a&gt;, &lt;a href=&quot;https://april.eecs.umich.edu/pdfs/olson2012rss.pdf&quot;&gt;max-mixture&lt;/a&gt;, and &lt;a href=&quot;http://n.ethz.ch/~cesarc/files/IROS2012_latif.pdf&quot;&gt;Realizing, Reversing, Recovering&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;running-g2o-with-external-library&quot;&gt;Running g2o with external library&lt;/h3&gt;

&lt;p&gt;g2o_viewer provides a flag, typeslib, to allow for the easy integration of external libraries.&lt;/p&gt;

&lt;h4 id=&quot;example--max-mixtues&quot;&gt;Example — max-mixtues&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;~/g2o_viewer -typeslib path-to-max-mixture/lib/libg2o_max_mix_core.so dataset.g2o

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;switchable-constraints&quot;&gt;Switchable Constraints&lt;/h2&gt;

&lt;h4 id=&quot;getting-switchable-contraints-to-run-on-ubuntu-1604&quot;&gt;Getting switchable contraints to run on Ubuntu 16.04&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git clone https://github.com/christiankerl/vertigo.git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;vertigo
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;mkdir build; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;build;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;G2O_INCLUDE_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'~/Documents/git/g2o/g2o/core'&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;G2O_LIBRARIES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'~/Documents/git/g2o/lib'&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;EDITOR ~/g2o/g2o/config.h

paste the following lines &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;config.h 

    &lt;span class=&quot;c&quot;&gt;#ifndef G2O_CONFIG_H&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#define G2O_CONFIG_H&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;#ifdef __cplusplus&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#include &amp;lt;g2o/core/eigen_types.h&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#endif&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;#endif&lt;/span&gt;


&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;EDITOR max_mixture/CMakeLists.txt

    copy the following line into CMakeLists.txt so that gcc knows to 
    compile the library with c++11. 


    &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;CMAKE_CXX_FLAGS &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CMAKE_CXX_FLAGS&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; -std=c++11&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;cmake ../; make 

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;switchable-constraints-test-1&quot;&gt;Switchable Constraints Test 1&lt;/h4&gt;

&lt;p&gt;To test switchable constraints, 100 false loop-closure constraints were added to the Manhattan 3500 data-set. The video below shows both the switchable constraints and traditional $L^2$ optimization ( switch constraints is shown on left ) attempting to minimize the graphs total error when the false loop-closures are present.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/utva9RHWCAE&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;max-mixtues&quot;&gt;Max-Mixtues&lt;/h2&gt;

&lt;h4 id=&quot;getting-max-mixtures-to-run-on-ubuntu-1604&quot;&gt;Getting max-mixtures to run on Ubuntu 16.04&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git clone https://github.com/agpratik/max-mixture.git
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;max-mixture
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;mkdir build; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;build;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;G2O_ROOT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'~/Documents/git/g2o'&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;EDITOR max_mixture/CMakeLists.txt

copy the following line into CMakeLists.txt so that gcc knows to 
compile the library with c++11. 


&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;CMAKE_CXX_FLAGS &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CMAKE_CXX_FLAGS&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; -std=c++11&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;cmake ../; make

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;max-mixture-test-1&quot;&gt;Max-Mixture Test 1&lt;/h4&gt;

&lt;p&gt;To test Max-Mixture, 100 false loop-closure constraints were added to the Manhattan 3500 data-set. The video below shows both the max-mix and traditional $L^2$ optimization ( max-mix is shown on left ) attempting to minimize the graphs total error when the false loop-closures are present.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/cBCCVR41-qY&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;max-mixture-vs-switchable-constraints&quot;&gt;Max-Mixture Vs. Switchable Constraints&lt;/h2&gt;

&lt;p&gt;A side by side comparision of max-mix and switch constrats was conducted. For this comparision, 1000 false loop-closure constraints were added to the Manhattan 3500 data-set. The video below shows the side by side optimization.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;Test RRR algorithm using g2o and manhattan dataset&lt;/p&gt;

</description>
        <pubDate>Wed, 17 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/summerafit/2017/05/17/Update.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/summerafit/2017/05/17/Update.html</guid>
        
        <category>summerAFIT</category>
        
        <category>max-mixtures</category>
        
        <category>switchable constraint</category>
        
        
        <category>_projects</category>
        
        <category>summerAFIT</category>
        
      </item>
    
      <item>
        <title>Testing Robust Noise Models</title>
        <description>&lt;h1 id=&quot;robust-noise-models&quot;&gt;Robust Noise Models&lt;/h1&gt;

&lt;h2 id=&quot;traditional-m-estimators&quot;&gt;Traditional M-Estimators&lt;/h2&gt;

&lt;p&gt;Traditional M-Estimators have been research for many years. The &lt;a href=&quot;http://sanghv.com/download/Soft/Machine%20Learning,%20Artificial%20Intelligence,%20Mathematics%20eBooks/math/statistics/robust%20statistics%20%282nd,%202009%29.pdf&quot;&gt;first comprehensive book&lt;/a&gt; on the subject was published by Huber in 1981.  The field of research related to M-estimation can be boiled down to reducing the influence of outliers by replacing the $L^2$ cost function with a modified cost function.&lt;/p&gt;

&lt;p&gt;So, M-Estimators replace the traditional $L^2$ cost,&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
$$ min \sum_i e_i^2 $$ 
&lt;/p&gt;

&lt;p&gt;with a modified cost function&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
$$ min \sum_i \rho(e_i) $$
&lt;/p&gt;

&lt;p&gt;One of the most important qualities of an M-Estimator is that the weight approaches 0 as the residual approachs $\infty$. This function property is call redescending and be defined more formally as&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
$$ \lim_{e_i \to \infty} \rho'(e_i) = 0 $$
&lt;/p&gt;

&lt;p&gt;A table of m-estimator cost functions is provided below. This table was taken from &lt;a href=&quot;http://www2.informatik.uni-freiburg.de/~agarwal/resources/agarwal-thesis.pdf&quot;&gt;this thesis&lt;/a&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;http://s1347.photobucket.com/user/rwatso12/media/m-estimators_zps3wyul65l.png.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/m-estimators_zps3wyul65l.png&quot; border=&quot;0&quot; alt=&quot; photo m-estimators_zps3wyul65l.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;graph-based-methods&quot;&gt;Graph Based Methods&lt;/h2&gt;

&lt;h4 id=&quot;switch-constraints--sc&quot;&gt;Switch Constraints  (S.C.)&lt;/h4&gt;

&lt;p&gt;Switchable constraints was introduced by Sunderhauf in 2012 in &lt;a href=&quot;https://www.tu-chemnitz.de/etit/proaut/mitarbeiter/rsrc/IROS12-switchableConstraints.pdf&quot;&gt;this paper&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The main idea behind the switchable constraints is that the topology of the factor graph that represents the pose graph SLAM problem, should be partially variable and subject to the optimization instead of being kept fixed. This way, edges representing outlier constraints can be removed from the graph during the optimization. This is achieved by augmenting the original problem and introducing an additional type of hidden variable: A switch variable is associated with each factor that could potentially represent an outlier. This additional variable acts as a multiplicative scaling factor on the information matrix associated with that constraint. Depending on the state of the switch variable (a value between 0 and 1), the resulting information matrix is either the original matrix (when the switch is equal to 1) or 0 (when the switch is 0) or something between both ends. Notice that if the switch variable is equal to 0, the associated constraint is completely removed and has no influence on the overall solution&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;dynamic-covariance-scaling--dcs&quot;&gt;Dynamic Covariance Scaling  (D.C.S.)&lt;/h4&gt;

&lt;p&gt;Dynamic Covariance Scaling was introduced in 2013 &lt;a href=&quot;http://www2.informatik.uni-freiburg.de/~spinello/agarwalICRA13.pdf&quot;&gt; in this paper &lt;/a&gt; as a closed-form solution to switch factors.&lt;/p&gt;

&lt;p&gt;The DCS approach reduces the confidence of an observable by de-weighting the corresponding element in the information matrix by the scale factor&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
$$ s_{ij} = min(1,\frac{2\Phi}{\Phi + \mathcal{X}}) $$
&lt;/p&gt;

&lt;p&gt;Ultimitely this is just the Geman-McClure weighting.&lt;/p&gt;

&lt;h4 id=&quot;max-mixtures--mm&quot;&gt;Max-Mixtures  (M.M)&lt;/h4&gt;

&lt;p&gt;Max-Mixtures was introduced in 2012 &lt;a href=&quot;https://april.eecs.umich.edu/pdfs/olson2012rss.pdf&quot;&gt; in this paper &lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The Max-Mixture model consists of a front-end loop-closure and null hypotheses. The front-end loop-closure hypothesis represents the distribution of the inlier loop-closure constraints and the null hypothesis represents the distribution of the outlier loopconstraints. Each loop-closure constraint is verified against the hypotheses iteratively within the optimization loops and the weight associated with the most likely hypothesis is used to scale the Jacobian, residual and information matrix from that loop-closure constraint. In other words, the hypothesis testing acts as an “selector” to the weighting of the loop closure constraint.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;REF&lt;/em&gt; $\rightarrow$ &lt;a href=&quot;https://www.inf.ethz.ch/personal/pomarc/pubs/LeeIROS13b.pdf&quot;&gt;this paper&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;realizing-reversing-recovering--rrr&quot;&gt;Realizing, Reversing, Recovering  (R.R.R)&lt;/h4&gt;

&lt;p&gt;RRR was introduced in 2012 &lt;a href=&quot;http://ai2-s2-pdfs.s3.amazonaws.com/1fca/9d6cbcccafbb6b1a2ee30cca5cc955eea1d6.pdf&quot;&gt; in this paper &lt;/a&gt;. This was then extended to an incremental estimator in &lt;a href=&quot;http://n.ethz.ch/~cesarc/files/IROS2012_latif.pdf&quot;&gt; this paper &lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;RRR divides
loop closures into clusters based on topological similarity and then tries to find the largest subset of clusters than are consistent among themselves as well as with the underlying odometry. Consistency is considered in the chi-squared ($\mathcal{X}^2)$ sense. The algorithm first carries out consistency checks for each cluster in order to weed out incorrect links within it, followed by an intra-cluster consistency check. RRR is different from the previous algorithms as it explicitly requires convergence of the graph in order to verify the validity of loop closures. In contrast with SC and DCS, in RRR and MM loop closure decisions are not modeled as continuous variables but as discrete yes/no decisions that need to be made&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;REF&lt;/em&gt; $\rightarrow$ &lt;a href=&quot;http://n.ethz.ch/~cesarc/files/IROS2014_latif.pdf&quot;&gt;this paper&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;comparison&quot;&gt;Comparison&lt;/h4&gt;

&lt;p&gt;A good paper comparing SC to DCS to RRR is provided by &lt;a href=&quot;https://www.tu-chemnitz.de/etit/proaut/forschung/rsrc/ICRA12-comparisonRobustSLAM.pdf&quot;&gt;Sunderhauf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The robust back-end formulation known as &lt;a href=&quot;https://www.tu-chemnitz.de/etit/proaut/mitarbeiter/rsrc/IROS12-switchableConstraints.pdf&quot;&gt;Switchable constraints&lt;/a&gt; was introduced by  Sunderhauf in 2012.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;noise-model-testing&quot;&gt;Noise Model Testing&lt;/h1&gt;

&lt;h3 id=&quot;data-set&quot;&gt;Data-set&lt;/h3&gt;

&lt;h4 id=&quot;clean-data&quot;&gt;Clean Data&lt;/h4&gt;
&lt;p&gt;The &lt;a href=&quot;http://rvsn.csail.mit.edu/graphoptim/eolson-graphoptim2006.pdf&quot;&gt;Manhattan world with 3500 nodes&lt;/a&gt; is a common graph optimization test data-set. The truth ground trace is shown in the figure below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.lucacarlone.com/images/M3500_eg2o.jpg&quot; alt=&quot;Man3500&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
True Manhattan wold 3500 ground truth 
&lt;/p&gt;

&lt;h4 id=&quot;adding-faults&quot;&gt;Adding faults&lt;/h4&gt;

&lt;p&gt;Gaussian noise with standard deviation 0.3rad is added to the relative orientation measurements.&lt;/p&gt;

&lt;h3 id=&quot;testing&quot;&gt;Testing&lt;/h3&gt;

&lt;p&gt;Using the erronous data, each of the noise models above will be tested. For all weighting functions, Levenberg Marquardt is utilized with a kernal width of 10.&lt;/p&gt;

&lt;h4 id=&quot;l2-cost-function&quot;&gt;$L^2$ Cost Function&lt;/h4&gt;
&lt;p&gt;First we will test the traditional $L^2$ minimization. A video of the optimizer going through 100 iterations is shown below.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Tb-hwRqCqkU&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;m-estimators&quot;&gt;M-Estimators&lt;/h3&gt;

&lt;h4 id=&quot;cauchy-cost-function&quot;&gt;Cauchy Cost Function&lt;/h4&gt;

&lt;p&gt;Next, we will test the Cauchy weighting function. A video of the optimizer going through 100 iterations is shown below.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/OtSKsQpCzlk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;geman-mcclure-cost-function&quot;&gt;Geman-McClure Cost Function&lt;/h4&gt;

&lt;p&gt;Now, a video of the optimization process with the Geman-McClure cost function.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/W7d3hNfppYc&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;saturaded-cost-function&quot;&gt;Saturaded Cost Function&lt;/h4&gt;

&lt;p&gt;Applying the saturated cost function to the optimization process&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/w7BsSpoQHQk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;tukey-cost-function&quot;&gt;Tukey Cost Function&lt;/h4&gt;

&lt;p&gt;Applying the tukey cost function to the optimization process&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/f7lK3frlVPk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;tukey-cost-function-1&quot;&gt;Tukey Cost Function&lt;/h4&gt;

&lt;p&gt;The last M-Estimator that will be tested is the Welcsh weighting. A video of the optimization process is shown below.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/lXHhbv2hFpM&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot; align=&quot;center&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;robust-graphical-methods&quot;&gt;Robust Graphical Methods&lt;/h3&gt;

</description>
        <pubDate>Tue, 16 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/summerafit/2017/05/16/Update.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/summerafit/2017/05/16/Update.html</guid>
        
        <category>summerAFIT</category>
        
        <category>m-estimator</category>
        
        <category>dcs</category>
        
        <category>switchable constraint</category>
        
        <category>rrr</category>
        
        
        <category>_projects</category>
        
        <category>summerAFIT</category>
        
      </item>
    
      <item>
        <title>Data Generation &amp; Initial Testing </title>
        <description>&lt;h1 id=&quot;data&quot;&gt;Data&lt;/h1&gt;

&lt;h2 id=&quot;simulated-data&quot;&gt;Simulated Data&lt;/h2&gt;
&lt;p&gt;Using &lt;a href=&quot;https://github.com/jsngross/WVUPNG/tree/master/matlab/pppINSSim&quot;&gt;PPP/INS&lt;/a&gt; simulator to generate GPS observables for two GNSS receivers, which are rigidly mounted to a platform. One receiver will be high fidelity ( i.e. final products with good models ) but the observables could have faults $ f \sim \mathcal{N}(0,25) $. The second receiver is lower fidelity ( positioning error $ \sim 15 m$ ); however, the observables generated by this receiver will have no faults.&lt;/p&gt;

&lt;p&gt;Generated 10 Hz GNSS observables for the flight profile depicted below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/flightPath_zps0hlmqd8z.png&quot; alt=&quot;ENU Path&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
Generated ENU flight profile
&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/velProfile_zps1njs5anz.png&quot; alt=&quot;ENU Velocity&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Generated ENU velocity profile
&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/attProfile_zpsf8v87zpg.png&quot; alt=&quot;Attitude&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Generated attitude profile
&lt;/p&gt;

&lt;h2 id=&quot;collected-data-in-degraded-environment&quot;&gt;Collected Data in Degraded Environment&lt;/h2&gt;
&lt;p&gt;In addition to simulated data, &lt;a href=&quot;https://www.tu-chemnitz.de/projekt/smartLoc/gnss_dataset.html.en&quot;&gt;TU-Chemnitz&lt;/a&gt; has made available 4 high quality data-sets. Currenlty talking with &lt;a href=&quot;tim.pfeifer@etit.tu-chemnitz.de&quot;&gt;Tim&lt;/a&gt; to see if he can provide us with the raw INS measurements. A brief description of the data-set is provided in the table below. A more detailed description is provided in &lt;a href=&quot;https://www.tu-chemnitz.de/projekt/smartLoc/paper/reisdorf2016.pdf&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;table class=&quot;mbtablestyle&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Sensors&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Info&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Low Cost GPS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;U-Blox EVK-M8T    ( $\sim$ meter lever error )&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;High Quality GPS&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Novatel SPAN Differential  ( $\sim$ decimeter lever error )&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Odometry&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Camera&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5 Cameras on-board&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;initial-testing&quot;&gt;Initial Testing&lt;/h1&gt;

&lt;p&gt;For this initial test, we are assuming that we have one high quality receiver with erronous data, and one lower quality receiver with fault free data. With this data, we can construct the pose graph using the low quality receiver ( i.e. take the low quality receiver position as truth ) and optimze the position using the high fidelity receiver’s raw observables.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/initialGraph_zpsitvad4hw.png&quot; alt=&quot;Initial Graph&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Inital factor graph
&lt;/p&gt;

&lt;p&gt;In the graph, $e_i$ represents an error function or probabilistic constraints applied to the state at the specified time-step. When Gaussian noise is assumed, the error function is equivalent to the innovation residual of the traditional Kalman filter. Utilizing this information it is easy to see that the optimal state estimate can be calculated through a traditional non-linear least squares formulation ( i.e., Levenberg Marquardt ) that minimizes the error over the graph.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_i = H_i(X_i) - Z_i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{X} = argmin \sum_i  \lvert \lvert e_i \rvert \rvert^{2}_{\Sigma}&lt;/script&gt;

&lt;p&gt;Whenever errors are present in the observations, methods to make the optimization more robust must be incorporated. One such method is the switchable constraint, which can be thought of as an observation weight that is be optimized concurrently with the state estimates. The addition of the switchable constraint to the optimization processes modifies the cost function. The modified cost function is provided below, where s is the switchable constraint which is confined to the interval of zero to one. A graphical depiction of this is shown in the Figure below, where observable $m$ at epoch $n$ exceeded the pre-defined residual threshold.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{X} = argmin \sum_i  \lvert \lvert e_i \rvert \rvert^{2}_{\Sigma} + \sum_i  \lvert \lvert s_i * e_i \rvert \rvert^{2}_{\Sigma} + \sum_i  \lvert \lvert 1 - s_i \rvert \rvert^{2}_{\Xi}&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;http://i1347.photobucket.com/albums/p701/rwatso12/switchGraph_zpstxvtoyp7.png&quot; alt=&quot;Switch Factor Graph&quot; align=&quot;middle&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
Graph with switch factors incorporated
&lt;/p&gt;

&lt;h2 id=&quot;sensitivity-testing&quot;&gt;Sensitivity Testing:&lt;/h2&gt;

&lt;h3 id=&quot;1-faults-randomly-added-to-observables-&quot;&gt;1) Faults randomly added to observables :&lt;/h3&gt;

&lt;h3 id=&quot;2-slowing-increase-magnitude-of-fault-on-specific-satellite--&quot;&gt;2) Slowing increase magnitude of fault on specific satellite  :&lt;/h3&gt;

&lt;h1 id=&quot;to-be-continued-&quot;&gt;To Be Continued …&lt;/h1&gt;

</description>
        <pubDate>Mon, 15 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/summerafit/2017/05/15/Update.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/summerafit/2017/05/15/Update.html</guid>
        
        <category>summerAFIT</category>
        
        <category>data generation</category>
        
        <category>switchable constraint</category>
        
        
        <category>_projects</category>
        
        <category>summerAFIT</category>
        
      </item>
    
      <item>
        <title>Full Math Support</title>
        <description>&lt;p&gt;For scientific writing Math is essential. That is why I added &lt;a href=&quot;http://www.mathjax.org/&quot;&gt;Mathjax&lt;/a&gt; to render all your beautiful equations inline, $ f(x) = a x^\alpha $, or as blocked equation element&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J_\alpha(x) = \sum\limits_{m=0}^\infty \frac{(-1)^m}{m! \, \Gamma(m + \alpha + 1)}{\bigl({\frac{x}{2}}\bigr)}^{2 m + \alpha}&lt;/script&gt;

&lt;p&gt;Have fun!&lt;/p&gt;
</description>
        <pubDate>Mon, 15 May 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/researchNotes/_projects/labupdates/2017/05/15/full-math-support.html</link>
        <guid isPermaLink="true">http://localhost:4000/researchNotes/_projects/labupdates/2017/05/15/full-math-support.html</guid>
        
        <category>labUpdates</category>
        
        
        <category>_projects</category>
        
        <category>labUpdates</category>
        
      </item>
    
  </channel>
</rss>
