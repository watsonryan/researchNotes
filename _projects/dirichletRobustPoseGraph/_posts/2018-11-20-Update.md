---
title: "Testing Covarince Matrix Priors"
layout: post
date: "2018-11-20"
author: Ryan Watson
tags:
  - dirichletRobustPoseGraph
  - Covariance Prior
---

<bf> References: </bf>
<a href="https://arxiv.org/pdf/1408.4050.pdf"> 1) Alvarez, Ignacio, Jarad Niemi, and Matt Simpson. "Bayesian inference for a covariance matrix." arXiv preprint arXiv:1408.4050 (2014).</a>



# Problem setting

When utilizing Bayesian inference, a core interest is the calculation of the posterior distribution. This calculation is generally made difficult -- if not intractable -- by the requirement to calculate the marginal likelihood (i.e., the denominator of Bayes theorem, as depicted below).

$$p(\theta | x) = \frac{p(x|\theta)p(\theta)}{p(x)} \quad \text{where} \quad p(x)  = \int p(x | \theta)p(\theta) d\theta$$

To make this calculation tractable ( actually analytical ), we need to intelligently select priors.

##  The Inverse Wishart Prior

The inverse Wishart (IW) density is defined as

$$\Sigma \sim \mathcal{W}^{-1} \quad \text{if} \quad p(\Sigma) \propto |\Sigma|^{-(\nu+d+1)/2} e^{\frac{1}{2}tr(\Lambda \Sigma^{-1})}, $$

where $\Lambda$ is a P.D. d-dimensional matrix, and $\nu$ is the degrees-of-freedom. This prior makes the assumption that each variance term is from a inverse chi-square distribution. This distribution can easily be sampled from using the <a href="https://en.wikipedia.org/wiki/Wishart_distribution"> Barlett decomposition</a>, as presented below.

<br>

~~~~~~~~
    """ Bartlett decomposition based sampling """
    def wishartrand(self):
        dim = self.inv_psi.shape[0]
        chol = np.linalg.cholesky(self.inv_psi)
        foo = np.zeros((dim, dim))

        for i in range(dim):
            for j in range(i + 1):
                if i == j:
                    foo[i, j] = np.sqrt(chi2.rvs(self.nu - (i + 1) + 1))
                else:
                    foo[i, j] = np.random.normal(0, 1)
        return np.dot(chol, np.dot(foo, np.dot(foo.T, chol.T)))
~~~~~~~~

<br>

Utilizing the implementation presented above, we can sample the prior distribution. For this evaluation, we sampled the inverse Wishart prior 10,000 times with hyperparameters set as $\nu = d+1$, and $\Lambda = I$. The figure shows the first and second variance terms with the color corresponding the the magnitude of correlation between the two terms. From this figure, we can see a clear correlation between variance and correlation.

<p align="center">
<a href="https://lh3.googleusercontent.com/RT0l9KRp3Vh0glGZAkpxD7ieIU4LaBUlGyTZQz6Ks377HXq1Gji0yxKAeaiA99b-_GoZj5Gxq3sKimTqGhgaFG52VkDL3m5B0yGbJ913RiT_5Byb8mqBkOLT6_XgDwwM6rF54uqi-iS7AW-IL82DfC9WrXyGnG5DB_LhTDmlxrMKCsAJaTQJCXmo8FJjznxIxYBtCgWNwHouxTPSA4234ytPOwAElBnZFFXbB6JBS9c9h0Sm3b4sjbzm0JLNC4Ng_gpPZpN8silQLA8G8toKA8zP5irFGROvlJrOt0CnPs7sPlnpfKmj3LiyWr9T_L5Ii9D_74Nwa1mJviupDNFv13zltY2hArOKgm4Lfb0xhsiiwAGknDwUglGN79FIb8UvdQobC2SPu0JDqjDeB2BOfKiapSg52uCJIZzhjTP-XqoHWxcrQhYsVbhebveKOtQY0bgd1YOk4N2YAPuoXRW0sRCqmOqswTCnN6M6_JGxgDUfIZ52F0hZQ6g-Y_qdV-eoi7EIYZRCnRk-1zR6wauUHJm3cngVbrkg-XT4OG0FLh3egNtGvYegh4iCpV8wAYsM9Q8GH1lHPt2opuxNL_rQaaSOy_KWChyQCrPSwkoxYuRSp4O45Rp6VhkZjjG37lJwRFkYRCZZIK8hWpo2jmvTC-afgVg_GeeLNWHGyaIdpfKLUf1dl69631abBvjW8wlC1ftKuYRDmW2PvR7yTg=w1227-h879-no" target="_blank"><img src="https://lh3.googleusercontent.com/RT0l9KRp3Vh0glGZAkpxD7ieIU4LaBUlGyTZQz6Ks377HXq1Gji0yxKAeaiA99b-_GoZj5Gxq3sKimTqGhgaFG52VkDL3m5B0yGbJ913RiT_5Byb8mqBkOLT6_XgDwwM6rF54uqi-iS7AW-IL82DfC9WrXyGnG5DB_LhTDmlxrMKCsAJaTQJCXmo8FJjznxIxYBtCgWNwHouxTPSA4234ytPOwAElBnZFFXbB6JBS9c9h0Sm3b4sjbzm0JLNC4Ng_gpPZpN8silQLA8G8toKA8zP5irFGROvlJrOt0CnPs7sPlnpfKmj3LiyWr9T_L5Ii9D_74Nwa1mJviupDNFv13zltY2hArOKgm4Lfb0xhsiiwAGknDwUglGN79FIb8UvdQobC2SPu0JDqjDeB2BOfKiapSg52uCJIZzhjTP-XqoHWxcrQhYsVbhebveKOtQY0bgd1YOk4N2YAPuoXRW0sRCqmOqswTCnN6M6_JGxgDUfIZ52F0hZQ6g-Y_qdV-eoi7EIYZRCnRk-1zR6wauUHJm3cngVbrkg-XT4OG0FLh3egNtGvYegh4iCpV8wAYsM9Q8GH1lHPt2opuxNL_rQaaSOy_KWChyQCrPSwkoxYuRSp4O45Rp6VhkZjjG37lJwRFkYRCZZIK8hWpo2jmvTC-afgVg_GeeLNWHGyaIdpfKLUf1dl69631abBvjW8wlC1ftKuYRDmW2PvR7yTg=w1227-h879-no" border="0" alt="man3500Take2 photo imgonline-com-ua-twotoone-WnIIlEQy1RfDp_zpsulmdqymy.jpg"/></a>
</p>
<p align="center">
Fig 1 :: Sampling from Inverse Wishart Prior  
</p>
<br>


## The Scaled Inverse Wishart Prior

One possible covariance prior, which may allow us to overcome the dependency between variance and correlation terms is the <a href="http://www.stat.columbia.edu/~gelman/stuff_for_blog/omalley.pdf">, scaled inverse Wishart (SIW) </a>. This prior also has the added benefit of allowing prior information to be incorporated about the individual standard deviation components

We can define the scaled inverse Wishart as $\Sigma := \Delta Q \Delta$, where $\Delta_{ii} = \delta_i$. The density for $Q$ and $\Delta$ is defined below.

$$ Q \sim \mathcal{W}^{-1}(\nu, \Lambda) \quad \text{and} \quad log(\delta_i) \sim \mathcal{N}(b_i, \zeta_i^2) $$

The scaled inverse wishart can be sampling utilizing to code presented below.

<br>

~~~~~~~~
    """ Scaled Inverse Wishart """
    def siw(self):
      Q = invwishart.rvs(self.dim, self.scale)
      D = norm.rvs(self.mean, self.var, self.dim)

      siw = np.zeros(shape=(self.dim, self.dim))
      for j in range(0, self.dim):
          for k in range(0, self.dim):
              if j is k:
                  siw[j, k] = np.exp(D[j]) * np.sqrt(Q[j, j])
              else:
                  siw[j, k] = D[j] * D[k] * Q[j, k]
      return siw
~~~~~~~~

<br>

Again, utilizing the implementation presented above, we can sample the prior distribution. For this evaluation, we sampled the scaled inverse Wishart prior 10,000 times with hyperparameters set as $\nu = d+1$, and $\Lambda = 0.8I$, $b=0$, $\zeta=1$. The figure shows the first and second variance terms with the color corresponding the the magnitude of correlation between the two terms. From this figure, we can clearly see less of a correlation between the variance and correlation terms, when compared to the inverse Wishart.


<p align="center">
<a href="https://lh3.googleusercontent.com/fxrLO-rKHd2UcfPi3RLmluWgFxgoQyD5kwTVxDGBNISjWWW4xVQD0Gmpqc1jk2qtCiBtnkDEJKxibA22T-sZKXGE0lmLuJVO4EV32SAsNms04npiqp-S8RD1hGf9qEV7r6vFwGwxJhNynYWIRnQLkBspiC5mlJkLpWevI2YsFbSklOxKOliCb3-tOBVTWcZrhvLsYUsMWAX-9v_OC9FgKoVdely3bKQ0YnFBlhCEwJHq1hiWYks-ua1Y0YkcE4hu-3OA64Kj2MQPmTOcoz7eKwiKChUvGauZpo4TboY1mUziWDeSXXwLCIrNPWskFsCor_CBx-vb3s7AOAeLnstaOHVAiuYbyEnZd_RwtNVt-BDFex3FNOshHRGSwlpgHRzua-QY5MeK_WoVVCliuL5EVaPUZEALusXCEpe0gKryVxKorwNPsc53DNkG4TKox8lojyq3oWvgUOU1qBAgCtyLZCK1xwruqOoZFeYDbO9SWi5tq3s-rJEtXz2nAVHIYbE75J96NyKmkTlUoHfL2RGyjKlGcHsIQFl5EZatmheAn-wMSOA2WOJTUJxKcogzB6JElYWvp5LOvsAivUKlPsY0Z1oI2vqfuU0u7k0aXnBLtsfPgoOGIgVNTP0eoilIcRwcCg7P9sX-COJ-7QeHsbQvL8iMHOC1tv52Zx6tfTzn4nZz8yq-Q67yaW3saj3lz5jULEec-TYbVQ7vxlKFiw=w1227-h879-no" target="_blank"><img src="https://lh3.googleusercontent.com/fxrLO-rKHd2UcfPi3RLmluWgFxgoQyD5kwTVxDGBNISjWWW4xVQD0Gmpqc1jk2qtCiBtnkDEJKxibA22T-sZKXGE0lmLuJVO4EV32SAsNms04npiqp-S8RD1hGf9qEV7r6vFwGwxJhNynYWIRnQLkBspiC5mlJkLpWevI2YsFbSklOxKOliCb3-tOBVTWcZrhvLsYUsMWAX-9v_OC9FgKoVdely3bKQ0YnFBlhCEwJHq1hiWYks-ua1Y0YkcE4hu-3OA64Kj2MQPmTOcoz7eKwiKChUvGauZpo4TboY1mUziWDeSXXwLCIrNPWskFsCor_CBx-vb3s7AOAeLnstaOHVAiuYbyEnZd_RwtNVt-BDFex3FNOshHRGSwlpgHRzua-QY5MeK_WoVVCliuL5EVaPUZEALusXCEpe0gKryVxKorwNPsc53DNkG4TKox8lojyq3oWvgUOU1qBAgCtyLZCK1xwruqOoZFeYDbO9SWi5tq3s-rJEtXz2nAVHIYbE75J96NyKmkTlUoHfL2RGyjKlGcHsIQFl5EZatmheAn-wMSOA2WOJTUJxKcogzB6JElYWvp5LOvsAivUKlPsY0Z1oI2vqfuU0u7k0aXnBLtsfPgoOGIgVNTP0eoilIcRwcCg7P9sX-COJ-7QeHsbQvL8iMHOC1tv52Zx6tfTzn4nZz8yq-Q67yaW3saj3lz5jULEec-TYbVQ7vxlKFiw=w1227-h879-no" border="0" alt="man3500Take2 photo imgonline-com-ua-twotoone-WnIIlEQy1RfDp_zpsulmdqymy.jpg"/></a>
</p>
<p align="center">
Fig 2 :: Sampling from Scaled Inverse Wishart Prior  
</p>
<br>


## Hierarchical Half-t Prior

Finally, we can test the <a href="http://matt-wand.utsacademics.info/publicns/Huang13.pdf">, hierarchical half-t prior</a>, which we will define the density as

$$ \Sigma \sim \mathcal{W}^{-1}(\nu+d-1, 2\nu\Lambda), $$

where $\Lambda$ is a diagonal matrix with $\Lambda_{i,i} = \lambda_i$ such that

$$ \lambda_i \sim Ga(\frac{1}{2}, \frac{1}{\zeta_i^2}).$$


<br>

~~~~~~~~
    """ Hierarchical Half-t Prior """
    def hiw(self):
      n = self.dim
      d = self.dof
      g = self.scale

      Lambda = np.diag(gamma.rvs(1.0 / 2.0, loc=0, scale=g, size=n))
      return invwishart.rvs(n + d - 1, 2 * d * Lambda)
~~~~~~~~

<br>

Utilizing the implementation presented above, we can sample the prior distribution. For this evaluation, we sampled the hierarchical half-t prior 10,000 times with hyperparameters set as $\nu=2$, and $\zeta = 1.04$. The figure shows the first and second variance terms with the color corresponding the the magnitude of correlation between the two terms.

<p align="center">
<a href="https://lh3.googleusercontent.com/X0RAAMrRdAHss9_8deO0sZVPWbQygYQ6ijTAFxo7BD2Ipg2Jv2Ib8yJBtewOBphf5RGzH8xCmKfDzJ3gviSuorXMg6s7BeEs0tNie6DCvFYeWtN1kfeaN4SZCclvihHkTfGCo7IctwpafSlrnzFczJGrW5hBueWB-5J3fJloHvk5WmmCN9b7A7oyL8fSY8MoX_Bj36I0rZ6CuB8RwWhpdjK_rxcLNYKK27qYz1rsQRErm2r-iulrdWDfZ5xNm3jSkUve_5Yekg_QfrkkEzPVvmogrJSCnhoPyFCV_9opy3HkFnDpx1QjUAdbj-O95yXT1dVFvcgni-z68wRdQRxTsjwi6mMUFh83O4vigcr6NuomqZmpNPxjm-MrE7FKDKlI8X3a8enar01J3t4_VTx25u1jnnyYP0yHglprIpfqRSynkr5SZXGxmykABr_lalRURWG1Ois51a_g96FoIeM-ccCs_qOMzCosqhB1TS3mUwpsuSS_74BYBgbg5obykTSjGv5lT1yUyXD_UmMUebM50JuhYNHRdwMQXnCaxfqSz5B2oUaxjKFS2Bk_Y9Pi4vjNUw7ZLiOKfFso8JFdSEvdgdtOzAa3TCn0fE4h0GA39bMtKCdEy9MWw0Shoq3vQ8ZcRKf-DCvEuaaCri1lDAZv8P_TuuWYuotIPgL2PKlK1RydAYArcYRMUaEc1po1bue9R3_aqpErGzNJNWmvwQ=w1227-h879-no" target="_blank"><img src="https://lh3.googleusercontent.com/X0RAAMrRdAHss9_8deO0sZVPWbQygYQ6ijTAFxo7BD2Ipg2Jv2Ib8yJBtewOBphf5RGzH8xCmKfDzJ3gviSuorXMg6s7BeEs0tNie6DCvFYeWtN1kfeaN4SZCclvihHkTfGCo7IctwpafSlrnzFczJGrW5hBueWB-5J3fJloHvk5WmmCN9b7A7oyL8fSY8MoX_Bj36I0rZ6CuB8RwWhpdjK_rxcLNYKK27qYz1rsQRErm2r-iulrdWDfZ5xNm3jSkUve_5Yekg_QfrkkEzPVvmogrJSCnhoPyFCV_9opy3HkFnDpx1QjUAdbj-O95yXT1dVFvcgni-z68wRdQRxTsjwi6mMUFh83O4vigcr6NuomqZmpNPxjm-MrE7FKDKlI8X3a8enar01J3t4_VTx25u1jnnyYP0yHglprIpfqRSynkr5SZXGxmykABr_lalRURWG1Ois51a_g96FoIeM-ccCs_qOMzCosqhB1TS3mUwpsuSS_74BYBgbg5obykTSjGv5lT1yUyXD_UmMUebM50JuhYNHRdwMQXnCaxfqSz5B2oUaxjKFS2Bk_Y9Pi4vjNUw7ZLiOKfFso8JFdSEvdgdtOzAa3TCn0fE4h0GA39bMtKCdEy9MWw0Shoq3vQ8ZcRKf-DCvEuaaCri1lDAZv8P_TuuWYuotIPgL2PKlK1RydAYArcYRMUaEc1po1bue9R3_aqpErGzNJNWmvwQ=w1227-h879-no" border="0" alt="man3500Take2 photo imgonline-com-ua-twotoone-WnIIlEQy1RfDp_zpsulmdqymy.jpg"/></a>
</p>
<p align="center">
Fig 2 :: Sampling from Scaled Inverse Wishart Prior  
</p>
<br>


# To Do:
- Need to test prior models in collapsed Gibb's sampling implementation to see their affect.
- Need to test separation strategy methods
