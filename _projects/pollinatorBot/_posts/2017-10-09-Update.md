---
title: "Initial Test of Dense RGB-D SLAM in Greenhouse"
author: Ryan Watson
date: "2017-10-09"
tags:
 - pollinatorBot
 - bumble bot
 - slam
 - rgb-d
 - blam test
---

<br><br>

# Testing Kintinuous

During the last data collect, we attached a Kinect to the pollinatorBot. Using the Kinect data we can test the dense rgb-d slam. The implementation we're currently testing is [Kintinuous](https://github.com/mp3guy/Kintinuous). The real-time playback of the algorithm is shown below in the first video. 


<br>
<p align="center">
<iframe width="640" height="360" src="https://www.youtube.com/embed/Scls6cwd04I" frameborder="0" allowfullscreen></iframe>
</p>
<br><br>
<p align="center">
<b> Inital test of Kintinuous on greenhouse dataset </b> 
</p>
<br><br>

After optimizing, we can extract the final dense map estimate, as depicted in Fig. 1. As you would expect from the video above, the final map solution does not provide an accurate representation of the greenhouse environment.


<br>
<p align="center">
<a href="https://lh3.googleusercontent.com/M2h7K56xK2Mbe2W5-Wzy_CG6AKE0tavMZxYnpWWJEs_tlyM-JEsHRII2r0PHsHj1aXDCRRYZEQtnkdFR9ldyfcb9iDDjBmm4exhqQhvCR8S2E3WyoiQiKzWOvxSi5B4QPsyALz24itHTANwSbZwn4NNfgOm7DCyhFV8lSoZuzxtYNeW-fKIgaLENvHH_Kl54FGiWH48JJoWHEZscisrRB5lyHJoD8wgvHBE3Ckg15EF74xv559M_jxzHEnzVDZ3PCNnm2p80qJKnbXfN6x303phmN8X3evwlFJchxsiXCwnNYx2_29iEJRNknlTQGJXYPYefo-3mIlqRzMiEzgXilbbKq5_MRll0HQKARlutHLDymvToqWXZ07SlM-HpLgUxxIkNVmM9qwU3MZcow5FLoZH4znOZ2Jnoz5hsRzVDey2QK2hw0qrsEEnRbYnFnRugLfnpmhwIaOxwEwmV7DT6VI4_wDPxZbom9Ic3EkaOB_llsTSdGT8oSVSrqvjWzs2jb9ax1GeNKrTH7M02VZ40rjWwMW8TcDQZiQQC7l_8VPdP8v0VL_xyiZTK3n8yGGPLyDOjkg13dFYkZzRWkyJ8hLTi9cIPFxUBefPO4s8zvI6DQhzGuVBG3wcsut3YE7f8DThJrGy-mShv2ez5DjIreJ0LhzYm9lCW83k=w1280-h751-no" target="_blank"><img src="https://lh3.googleusercontent.com/M2h7K56xK2Mbe2W5-Wzy_CG6AKE0tavMZxYnpWWJEs_tlyM-JEsHRII2r0PHsHj1aXDCRRYZEQtnkdFR9ldyfcb9iDDjBmm4exhqQhvCR8S2E3WyoiQiKzWOvxSi5B4QPsyALz24itHTANwSbZwn4NNfgOm7DCyhFV8lSoZuzxtYNeW-fKIgaLENvHH_Kl54FGiWH48JJoWHEZscisrRB5lyHJoD8wgvHBE3Ckg15EF74xv559M_jxzHEnzVDZ3PCNnm2p80qJKnbXfN6x303phmN8X3evwlFJchxsiXCwnNYx2_29iEJRNknlTQGJXYPYefo-3mIlqRzMiEzgXilbbKq5_MRll0HQKARlutHLDymvToqWXZ07SlM-HpLgUxxIkNVmM9qwU3MZcow5FLoZH4znOZ2Jnoz5hsRzVDey2QK2hw0qrsEEnRbYnFnRugLfnpmhwIaOxwEwmV7DT6VI4_wDPxZbom9Ic3EkaOB_llsTSdGT8oSVSrqvjWzs2jb9ax1GeNKrTH7M02VZ40rjWwMW8TcDQZiQQC7l_8VPdP8v0VL_xyiZTK3n8yGGPLyDOjkg13dFYkZzRWkyJ8hLTi9cIPFxUBefPO4s8zvI6DQhzGuVBG3wcsut3YE7f8DThJrGy-mShv2ez5DjIreJ0LhzYm9lCW83k=w1280-h751-no" border="0" alt=" photo imgonline-com-ua-twotoone-XEN5fUgMoaSc_zpsliygmo1g.jpg"/></a>
</p>
<p align="center">
Fig 1 :: Final map solution
</p>
<br>


#### Next Steps

1) We used a Kinect 2.0, which is known to provided degraded data in an outdoor setting. We should test another rgb-d sensor.

2) We can provide Kintinuous an initial pose-graph (i.e., provide it our lidar slam solution) so that it only has to reconstruct the dense map.

<br><br>
