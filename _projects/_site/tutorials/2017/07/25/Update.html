<h1 id="note-overview">Note Overview</h1>

<p>For this tutorial I was asked to provide a brief overview of Expectation Maximization (E.M.) and model selection. However, to begin, I will need to start with Maximum Likelihood Estimation (M.L.E.). With that in mind, this set of notes will be organized as follows. First, I will discuss M.L.E and provide a short example that links it back to equations we’ve seen before. Then, I will discuss the E.M. algorithm and give a few applications. Finally, I will briefly talk about model selection and give an applicable example.</p>

<p><br /></p>

<h1 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h1>

<p>Assume that we are given a dataset $Y= \lbrace y_i, \ldots, y_n \rbrace $ where $y_i \in \mathbf{R}^d,$ where Y’s probability distribution depends on some unknown parameter $\theta \in \Theta$. Then, the likelihood of obserserving this data given a value for $\theta$ is,</p>

<script type="math/tex; mode=display">lik(\theta, Y) = \prod_i^n p( y_i, \theta),</script>

<p>and the value of $\theta$ that makes our observed data the most probable is known as the M.L.E.</p>

<script type="math/tex; mode=display">\hat{\theta} = \text{argmax} \ \text{log} \ p( Y | \theta) = \sum_i^n \text{log} \ p(y_i | \theta)</script>

<h3 id="example----batch-estimation">Example – Batch Estimation</h3>

<p><br /><br /></p>

<p>As we have assume before, let’s suppose that we have a measurement model,</p>

<script type="math/tex; mode=display">\widetilde{y} = Hx + \nu \quad \text{where} \quad \nu = \mathcal{N}(0,R).</script>

<p>Because we have defined $\nu$ is Gaussian, $\widetilde{y}$ is also Gaussian. With that knowledge, we may describe the PDF of the measurements as,</p>

<script type="math/tex; mode=display">p(\widetilde{y}) = \frac{1}{(2\pi)^{n/2} ||R||^{1/2}} e^{-\frac{1}{2}(\widetilde{y} - E[\widetilde{y}])^T R^{-1}(\widetilde{y}-E[\widetilde{y}])}</script>

<p>where we will define the normalization constant as $c$ for the rest of this example.</p>

<p>Now, we can find the expectation of $\widetilde{y}$ as,</p>

<script type="math/tex; mode=display">E[\widetilde{y}] = E[Hx+\nu] = E[Hx] + E[\nu] = E[Hx] = Hx.</script>

<p>With this information we can represent the conditional probability of our measurements given our states,</p>

<script type="math/tex; mode=display">p(\widetilde{y} | x) = c e^{-\frac{1}{2}(\widetilde{y} - Hx)^T R^{-1}(\widetilde{y}-Hx)} .</script>

<p>As stated above, the goal of M.L.E is to find the state estimate, $\hat{x}$ that maximizes $p(\widetilde{y} | x)$, which is the likelihood that x resulted in the measurement of $\widetilde{y}$. This means that our objective function is</p>

<script type="math/tex; mode=display">\text{max}\ J(x) = c e^{-\frac{1}{2}(\widetilde{y} - Hx)^T R^{-1}(\widetilde{y}-Hx)} .</script>

<p>Now, we note that maximizing $ p( \widetilde{y} | x ) $ will result in the same solution as maximizing $ ln( p( \widetilde{y} | x ) ) $. Therefore, we modify the objective function by</p>

<script type="math/tex; mode=display">\text{max}\ J(x) = ln ( c e^{-\frac{1}{2}(\widetilde{y} - Hx)^T R^{-1}(\widetilde{y}-Hx)} ) \quad = \quad ln(c) -\frac{1}{2}(\widetilde{y} - Hx)^T R^{-1}(\widetilde{y}-Hx).</script>

<p>We can convert this to a minimization problem by negating the equation above,</p>

<script type="math/tex; mode=display">\text{min}\ J(x) = \frac{1}{2}(\widetilde{y} - Hx)^T R^{-1}(\widetilde{y}-Hx) - ln(c),</script>

<p>which expands to yield,</p>

<script type="math/tex; mode=display">\text{min}\ J(x) = \frac{1}{2} [\widetilde{y}^T R^{-1} \widetilde{y} - 2x^T H^T R^{-1} \widetilde{y} + x^T H^T R^{-1} H x ] - ln(c).</script>

<p>Now, we can apply the first differential condition,</p>

<script type="math/tex; mode=display">\frac{ \partial J(x) } { \partial x } = \frac{1}{2} [ -2 \widetilde{y}^{T} R^{-1} H + 2 x^T H^T R^{-1} H] = x^{T} H^T R^{-1} H - \widetilde{y} R^{-1} H = 0</script>

<script type="math/tex; mode=display">x^{T} H^{T} R^{-1} H = \widetilde{y}^T R^{-1} H</script>

<script type="math/tex; mode=display">\boxed{ \hat{x} = ( H^{T} R^{-1} H )^{-1} H^{T} R^{-1} \widetilde{y} }</script>

<p><br /></p>

<p>If we are also interested in the covariance of our estimate, we can find that easily too. We first note that the covariance of a state estimate is given by $P = E[(\hat{x}-\bar{x})(\hat{x}-\bar{x})^{T}].$</p>

<p>We can start by finding the expression for $\bar{x}$, which is given by,</p>

<script type="math/tex; mode=display">\bar{x} = E[\hat{x}] = E[( H^{T} R^{-1} H )^{-1} H^{T} R^{-1} (y+\nu)]  = ( H^{T} R^{-1} H )^{-1} H^{T} R^{-1} y.</script>

<p>Now, we can find an expression for $(\hat{x} - \bar{x}), $ which is</p>

<script type="math/tex; mode=display">\hat{x} - \bar{x} = ( H^{T} R^{-1} H )^{-1} H^{T} R^{-1}(y+\nu) - ( H^{T} R^{-1} H )^{-1} H^{T} R^{-1} y = (H^T R^{-1} H)^{-1} H^{T} R^{-1} \nu</script>

<p>Finally, plugging the above equation into the covariance equation yields,</p>

<script type="math/tex; mode=display">P = E[ (H^T R^{-1} H)^{-1} H^{T} R^{-1} \nu \nu^T R^{-1} H(H^{T} R^{-1} H)^{-1} ]</script>

<script type="math/tex; mode=display">\boxed{  = (H^{T}R^{-1}H)^{-1} }</script>

<p><br /></p>

<h4 id="additional-links">Additional Links</h4>
<ul>
  <li><a href="http://www.kamperh.com/notes/kamper_matrixcalculus13.pdf">Vector and Matrix Calculus Refresh</a></li>
  <li><a href="https://ocw.mit.edu/courses/mathematics/18-443-statistics-for-applications-fall-2006/lecture-notes/lecture3.pdf">MLE Properties</a></li>
</ul>

<p><br /><br /></p>

<h1 id="expectation-maximization">Expectation Maximization</h1>

<p>Now, we can move onto Expectation Maximization. Where it should be noted that, all this algorithm is doing is calculating and M.L.E for data when some variables are not observed.</p>

<h3 id="motivation-examples">Motivation Examples</h3>

<p>As shown above, if we are given a full dataset, we can pretty simple calculate a MLE. However, there are several applications where not provided all of the information need to fully characterize our problem. This issue segue us into the primary reason for utilizing E.M., which is to optimize is the presence of missing information. To provide a little motivation, I have provided two example applications.</p>

<h4 id="precise-gnss-data-processing">Precise GNSS Data Processing</h4>

<p>The first application is GNSS carrier-phase processing. When precise positioning of a platform is required and GNSS data is being utilized, the carrier-phase observable must be incorporated into your filtering algorithm. This carrier-phase observable can be thought of as a sinusoidal wave being propagated from the satellite to the user; however, you do not know the exact number of wave lengths that you are from the satellite. If the ambiguity can be resolved then cm level positioning is obtained.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/NO-bGGEP-AN3cVUoBDypQ1XRCgOdhutnLHiTA6LB4IlyNaTmThwGRQs-SvAk8rl_azQaGCH5aXE9gm0WbRNBOPwxFaSFpH6ndcCmz3PcT_ooPOdjcGcAQhUcWkDVEAvdG3lKg6pBH4jRZnX8F2_6J-W5Mxp0YuSWftwN3tBCQDCe8eLGIHccJduBIYAUK_3Osa7RMn9qwCgx8Ut-7ApEs4fR7647wtInZfExMrsl53Dhc_uRrLmNZMy1Stj5eYWZ-9vGVtRt3ogwVoYtgxrUt9DzPktrpGfkNwb_2kn4sMxDISqsUZdXJ0GBhyrQ4pcCsNEyDG46XONJdIZFlebPESPt77Q2or7VTZqmHJYdiQLdLE-gKRvTNt-W7XVT3K-mqPGpn6_fXoSe5Ek3C6ZwlcTI242oRdrL0quFxpFjIWrdO3ZK_jTs-XWKB2uuUZnaDhvEXbsUS8LsC3hbbsFBuOCKe4UKRnig5xdL1gDGEIyW7fCMNdsTPZCn8LhzIqs16iHv8mTjK_5kqW-RnT-PycN2BBVJ8GkM-TTLsJcsEymq22idG_5fDqez23zcjMf_fyEXoyGhrVL-I2BqonyL4UlPmokS1_aP-HkEbVjWQpl-l5H7sL1OKaObbFwAaBPC0O29uPu9-UxF-VIY10DCDH8SX-YFIcz73lWIAXAngI0dIw=w1033-h363-no" target="_blank"><img src="https://lh3.googleusercontent.com/NO-bGGEP-AN3cVUoBDypQ1XRCgOdhutnLHiTA6LB4IlyNaTmThwGRQs-SvAk8rl_azQaGCH5aXE9gm0WbRNBOPwxFaSFpH6ndcCmz3PcT_ooPOdjcGcAQhUcWkDVEAvdG3lKg6pBH4jRZnX8F2_6J-W5Mxp0YuSWftwN3tBCQDCe8eLGIHccJduBIYAUK_3Osa7RMn9qwCgx8Ut-7ApEs4fR7647wtInZfExMrsl53Dhc_uRrLmNZMy1Stj5eYWZ-9vGVtRt3ogwVoYtgxrUt9DzPktrpGfkNwb_2kn4sMxDISqsUZdXJ0GBhyrQ4pcCsNEyDG46XONJdIZFlebPESPt77Q2or7VTZqmHJYdiQLdLE-gKRvTNt-W7XVT3K-mqPGpn6_fXoSe5Ek3C6ZwlcTI242oRdrL0quFxpFjIWrdO3ZK_jTs-XWKB2uuUZnaDhvEXbsUS8LsC3hbbsFBuOCKe4UKRnig5xdL1gDGEIyW7fCMNdsTPZCn8LhzIqs16iHv8mTjK_5kqW-RnT-PycN2BBVJ8GkM-TTLsJcsEymq22idG_5fDqez23zcjMf_fyEXoyGhrVL-I2BqonyL4UlPmokS1_aP-HkEbVjWQpl-l5H7sL1OKaObbFwAaBPC0O29uPu9-UxF-VIY10DCDH8SX-YFIcz73lWIAXAngI0dIw=w1033-h363-no" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 1 :: Factor Graph With Only Pseudorange Observables   
</p>
<p><br /></p>

<p align="center">
<a href="https://lh3.googleusercontent.com/gTnmMmc_sAWel1lZQ5LJXxeSPE999WuMpyFt-7qWdw1yhWanjMGYy7QH4cR5On29K5-kj5LXjy4voOGRZQCqLtJFMZZVYmQCpygft5XcFDWCyNH-UXvMdW-u7MIMsEAVkI3HFJINmWbiP6-JG-ws0glkf0e8icBiWQxqOcqbpwJxiMx8AnQBKxHEbKHCy2FuqBb7qjJ66PHvnpt-k9gq02d024sIzKF3Bqrk_2MQD7l4k7J_mQXZb0AmJhufnGLuA3PZNbfg_kX56-gGZnvz5FAspJZgqxGUMa7UBtgNxLw9-3Aj727oGqt9FAg7eubLY9QRjy-2AS2rwPI8vsBMY7G_nhuXeRfpAdKkoKUNwmDZhc7JiMbJxTQid223Xz6MpTWD01CePfM8asMm5tfke-mTzH8EzdSCT3A3liIJnRAsQi1yyt7dXVjV-bXqoLM4wRBsukM9VxjTnRRjpcneZx4ieTM0MzJLta_oEuKDZeT4IkC10s05o6LaClECsuLo7gGIYlc0IGWWvutLVxLnyaif6TE-VT0Q1o1T_4j-bPA_p7jIGG2FJBKa5RdaFmVszNJVB2-bTV4wDH2ZmhPt1djAhXtPQns8QEjw5ZgjQu0D_bXaccUlsUI1VEdF9m8PASYqWSkRq224EwS-xFbkmQLYze1sWVhab6AdLFG2zV00ZA=w1033-h432-no" target="_blank"><img src="https://lh3.googleusercontent.com/gTnmMmc_sAWel1lZQ5LJXxeSPE999WuMpyFt-7qWdw1yhWanjMGYy7QH4cR5On29K5-kj5LXjy4voOGRZQCqLtJFMZZVYmQCpygft5XcFDWCyNH-UXvMdW-u7MIMsEAVkI3HFJINmWbiP6-JG-ws0glkf0e8icBiWQxqOcqbpwJxiMx8AnQBKxHEbKHCy2FuqBb7qjJ66PHvnpt-k9gq02d024sIzKF3Bqrk_2MQD7l4k7J_mQXZb0AmJhufnGLuA3PZNbfg_kX56-gGZnvz5FAspJZgqxGUMa7UBtgNxLw9-3Aj727oGqt9FAg7eubLY9QRjy-2AS2rwPI8vsBMY7G_nhuXeRfpAdKkoKUNwmDZhc7JiMbJxTQid223Xz6MpTWD01CePfM8asMm5tfke-mTzH8EzdSCT3A3liIJnRAsQi1yyt7dXVjV-bXqoLM4wRBsukM9VxjTnRRjpcneZx4ieTM0MzJLta_oEuKDZeT4IkC10s05o6LaClECsuLo7gGIYlc0IGWWvutLVxLnyaif6TE-VT0Q1o1T_4j-bPA_p7jIGG2FJBKa5RdaFmVszNJVB2-bTV4wDH2ZmhPt1djAhXtPQns8QEjw5ZgjQu0D_bXaccUlsUI1VEdF9m8PASYqWSkRq224EwS-xFbkmQLYze1sWVhab6AdLFG2zV00ZA=w1033-h432-no" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 2 :: Factor Graph With Pseudorange and Carrier-Phase Observables   
</p>
<p><br /></p>

<h4 id="data-clustering">Data Clustering</h4>

<p>The second example is a form of soft data clustering. In this example, we have a dataset with an unknown number of clusters. We can utilize E.M. to perform soft-clustering of each data point.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/kjMOEB0ZAhcftehuFgN6f5vCBdniVXqHbKK4dmscEV28MG91e6UIo8O1NwrxCZ-NSvAr_YCkGfv09FohZLp0nR5GWF6qf3x5qeVB1aUSTsvEI0c_8y3RRetHlQizBrY8_CSexaXj5dyWheItEqp9O_0coqtG2BN0RMRdrCCygIuAAyA-jhFVP4tomFf9TI_LeKVjDckXcs27figec28IJfDAJMmlvJyvRDeeW8zSEfvW92j_ED-YL_ZqOE59gNhrhIpIkJusBUGGdxhfGIB8DOXYYsJaNSbFUwEVjomDWbc5Griat2BClJVLCRU6UCWWUjTmUqyuEfxNgMlBD6bezE2E7QoRpX2NLqxuP95YcYAu-CCReGIAJ_DQj4UAqK3C14v85AUvTcYbh9tzcGsLzSc0rlKzrtROEY0nQ9T5dka3RFMFgEaBFz4YN5_-8M-vNH1EQF_0mvs8IuZmyG6rcBvKvrMSzUFk_DXTyae6JnzVBCcl0HLAag4jEqtMhkUNR18NWanROfsTMBrnolELnViF4oRE1a5WR13ENURHPl3fE6WsJrxuakAPHo4Ix5beEMNQUj4lH37Esit0G1YAbGI-IEwlex4IwVBux93AArU1gKJlW2k3KpKGGF5ERb-AiwyebpwJORTT_rqeDuN-e6F3fVmX-FSgtfhkfyMJ7YMoUA=w1024-h539-no
" target="_blank"><img src="https://lh3.googleusercontent.com/kjMOEB0ZAhcftehuFgN6f5vCBdniVXqHbKK4dmscEV28MG91e6UIo8O1NwrxCZ-NSvAr_YCkGfv09FohZLp0nR5GWF6qf3x5qeVB1aUSTsvEI0c_8y3RRetHlQizBrY8_CSexaXj5dyWheItEqp9O_0coqtG2BN0RMRdrCCygIuAAyA-jhFVP4tomFf9TI_LeKVjDckXcs27figec28IJfDAJMmlvJyvRDeeW8zSEfvW92j_ED-YL_ZqOE59gNhrhIpIkJusBUGGdxhfGIB8DOXYYsJaNSbFUwEVjomDWbc5Griat2BClJVLCRU6UCWWUjTmUqyuEfxNgMlBD6bezE2E7QoRpX2NLqxuP95YcYAu-CCReGIAJ_DQj4UAqK3C14v85AUvTcYbh9tzcGsLzSc0rlKzrtROEY0nQ9T5dka3RFMFgEaBFz4YN5_-8M-vNH1EQF_0mvs8IuZmyG6rcBvKvrMSzUFk_DXTyae6JnzVBCcl0HLAag4jEqtMhkUNR18NWanROfsTMBrnolELnViF4oRE1a5WR13ENURHPl3fE6WsJrxuakAPHo4Ix5beEMNQUj4lH37Esit0G1YAbGI-IEwlex4IwVBux93AArU1gKJlW2k3KpKGGF5ERb-AiwyebpwJORTT_rqeDuN-e6F3fVmX-FSgtfhkfyMJ7YMoUA=w1024-h539-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 3 :: Soft Clustering Using E.M.   
</p>
<p><br /></p>

<h3 id="brief-intuitive-explanation">Brief Intuitive Explanation</h3>

<p>Expectation Maximization is an iterative optimization method. This method is incredible similar to that of M.L.E., in that its aim is to estimate the unknown parameters $\theta$, given the set of measurements, Y; however, now we have missing information N. So, with E.M., we want to maximize the posterior probability of the parameters $\theta$ given the data Y, marginalizing over N:</p>

<script type="math/tex; mode=display">\Theta^* = \text{argmax} \sum_N P( \Theta, N | Y)</script>

<p>In the next section, a slightly more informative discussion on E.M. is provided. Specifically, we will discuss expectation maximization is in the context of a <a href="http://www.cs.toronto.edu/~fritz/absps/emk.pdf">lower bound maximization</a>. That is, we can think of the expectation step as calculating a lower bound to the posterior distribution. Then, the maximization step is optimizing our bound, which improves the estimate for the unknowns.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/q2SzOD_7uDGsctzfXjdpbFRREfEH2oi3nYGmqX0vjwmssQw-1ExI7c8qSo4XR5FhnW5JhwzyNW6EGLFbLSzU4_yUHcYkwg9aR8BzCi0EG9dFD_USO4bVW0qbfvDIP8o9quuAxEPtYgVDozei523DMImle2hVdj5S9Gabkj5uIGiuyeDZgxPBZsTAjDJDZxzQK87G6Uh9eZKsa5hSHFVYrXrabdSaaPvNHy5EHoE6L2oLjdA0_QwVMm_w0VUrdLTzVuQveT_rJhRFwG4f1S_klChbDmOu7k8JVVNVHLPf1igVeihnC5w7OcfKSJSlbf3jOwLvb0HV73WvcB_ngP_YRPURdx-rBgVpUsyso5rIaO7wzpTGND9ypToffzoOup9fW9RKIIPX6TV88OiERQq8QnkpXsAjpCdWiC-myF19EGMB1ESVsMTsRtai0klN48FdaMOSrYs-ti20XN44p5Z7QF1GEUbCE-ECLcYqzpjMRKNy5YouuhJdFctINdSUi4cZvmzsjW0uEXtiuqc0JZus92rSaRlKXMYph0GkAKEt5UGuZNjO8mf9tfF1RcJCD1sF-XBd2rJq2G__FdrXQ5Z8L2IFETnoM4eMoi3vdkwTlIMvgBQA0aV9WEu592b4QqI6V1lvl9ehMoLpRul9M9sNn1X31clwKOEHBxzrtdGQpn72sA=w1096-h616-no
" target="_blank"><img src="https://lh3.googleusercontent.com/q2SzOD_7uDGsctzfXjdpbFRREfEH2oi3nYGmqX0vjwmssQw-1ExI7c8qSo4XR5FhnW5JhwzyNW6EGLFbLSzU4_yUHcYkwg9aR8BzCi0EG9dFD_USO4bVW0qbfvDIP8o9quuAxEPtYgVDozei523DMImle2hVdj5S9Gabkj5uIGiuyeDZgxPBZsTAjDJDZxzQK87G6Uh9eZKsa5hSHFVYrXrabdSaaPvNHy5EHoE6L2oLjdA0_QwVMm_w0VUrdLTzVuQveT_rJhRFwG4f1S_klChbDmOu7k8JVVNVHLPf1igVeihnC5w7OcfKSJSlbf3jOwLvb0HV73WvcB_ngP_YRPURdx-rBgVpUsyso5rIaO7wzpTGND9ypToffzoOup9fW9RKIIPX6TV88OiERQq8QnkpXsAjpCdWiC-myF19EGMB1ESVsMTsRtai0klN48FdaMOSrYs-ti20XN44p5Z7QF1GEUbCE-ECLcYqzpjMRKNy5YouuhJdFctINdSUi4cZvmzsjW0uEXtiuqc0JZus92rSaRlKXMYph0GkAKEt5UGuZNjO8mf9tfF1RcJCD1sF-XBd2rJq2G__FdrXQ5Z8L2IFETnoM4eMoi3vdkwTlIMvgBQA0aV9WEu592b4QqI6V1lvl9ehMoLpRul9M9sNn1X31clwKOEHBxzrtdGQpn72sA=w1096-h616-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 4 :: EM as Lower Bound
</p>
<p><br /></p>

<h3 id="em-as-lower-bound-optimization">E.M. as Lower Bound Optimization</h3>

<p>Again, the premise of EM is to start with a guess $\Theta^i$ for the parameters $\Theta$, compute an easily computed lower bound $B(\Theta | \Theta^t)$ to the function $ \text{log} \ P( \theta | Y) $, and maximize that bound instead. If iterated, this procedure will converge to a MLE $\Theta^*$ of the objective function.</p>

<p>So, our goal is to maximize the likelihood of our parameter vector $\theta$ given the data, Y, and the unknown parameters, N.</p>

<script type="math/tex; mode=display">\Theta^* = \text{argmax} \ log \ P(Y | \Theta) = \text{argmax} \ log \ \sum_N P(Y,N,\Theta)</script>

<p>Currently, this equation not easily solvable because it includes the logarithm of a summation. So, let’s manipulate it slightly to see if we can find a tractable bound.</p>

<script type="math/tex; mode=display">log \ P(Y | \Theta) = \ log \ \sum_N P(Y,N,\Theta) = \text{log} \sum_N f^t(N) \frac{P(Y,N,\Theta)}{f^t(N)}</script>

<p>Where, for now, we can just say that f^t(N) is an arbitrary probability distribution of the space of N.</p>

<p>Now, by applying Jensen’s inequality, we have</p>

<blockquote><div style="background-color:#FFFF00; color:#000000; font-style: normal; font-family: Georgia;">
Jensen's Inequality for Log :: <br /><br />

If 
$$ \sum_i \lambda_i = 1 $$

 Then, 

$$ ln \sum_i \lambda_i Q_i \geq \sum_i \lambda_i ln Q_i $$

</div></blockquote>

<script type="math/tex; mode=display">B(\Theta, \Theta^t) := \sum_N f^t(N) \ \text{log} \ \frac{P(Y,N,\Theta)}{f^t(N)} \leq \ \text{log} \sum_N f^t(N) \frac{P(Y,N,\Theta)}{f^t(N)}</script>

<p><br /></p>

<h4 id="how-do-we-find-an-optimal-bound">How do we find an optimal bound?</h4>

<p>The E.M. algorithm not only finds a lower bound, it finds the optimal one ( i.e., it finds the lower bound that touches the likelihood curve at the current estimate for $\Theta^t$. )</p>

<script type="math/tex; mode=display">B(\Theta^t, \Theta^t) = \sum_N f^t(N) \ \text{log} \ \frac{P(Y,N,\Theta)}{f^t(N)}</script>

<p>Now, this becomes a constrained optimization problem because $\sum_N f^t(N) = 1.$ So, to solve for the optimal bound, Lagrange Multipliers must be introduced.</p>

<p>That is, we must find a new cost function that takes the form of</p>

<script type="math/tex; mode=display">min J'(x_1,x_2,\lambda) = \phi(x_1,x_2) + \lambda \psi(x_1,x_2).</script>

<p>So, let’s define $\phi,$ and $\psi$ as</p>

<script type="math/tex; mode=display">\phi = \sum_N f^t(N) \ \text{log} \ \frac{P(Y,N,\Theta)}{f^t(N)},</script>

<p>and</p>

<script type="math/tex; mode=display">\psi = 1 - \sum_N f^t(N).</script>

<p>Now, we can define our new cost function as,</p>

<script type="math/tex; mode=display">J'(f^t) = \sum_N f^t(N) \ \text{log} \ \frac{P(Y,N,\Theta)}{f^t(N)} + \lambda[1-\sum_N f^t(J)] .</script>

<p>Take the derivative,</p>

<script type="math/tex; mode=display">\frac{ \partial J'}{ \partial f^t(N)} =  \text{log} \ P(Y,N,\Theta^t) - \text{log} f^t(N) - 1 - \lambda,</script>

<p>and solve for $f^t(N)$</p>

<script type="math/tex; mode=display">f^t(N) = \frac{P(Y,N,\Theta^t)}{\sum_N P(Y,N,\Theta^t)} = P(N | Y,\Theta^t).</script>

<p>Now, plugging this expression back into the first equation in this section, we get</p>

<script type="math/tex; mode=display">B(\Theta^T , \Theta^t) = \sum_N P(N | Y, \Theta^t) \ \text{log} \ \frac{P(Y,N,\Theta^t)}{P(N | Y,\Theta^t)} = \text{log} P(Y,\Theta^t)</script>

<p><br /></p>

<h4 id="how-do-we-optimize-this-bound">How do we optimize this bound</h4>

<p>First, let’s start with the bound,</p>

<script type="math/tex; mode=display">B(\Theta, \Theta^t) = \sum_N P(N | Y,\Theta^t) \ \text{log} \frac{P(Y,N,\Theta)}{P(N|Y,\Theta^T)}</script>

<script type="math/tex; mode=display">= \sum_N P(N|Y,\Theta^t) \ \text{log} P(Y,N,\Theta) -\sum_N P(N|Y,\Theta^t) \ \text{log} \ P(N|Y,\Theta^t)</script>

<script type="math/tex; mode=display">= \sum_N P(N|Y,\Theta^t) \ \text{log} P(Y,N,\Theta) - \mathcal{H}</script>

<script type="math/tex; mode=display">= \sum_N P(N|Y,\Theta^t) \ \text{log} P(Y,N | \Theta) + \text{log} P(\Theta) - \mathcal{H}</script>

<script type="math/tex; mode=display">= Q^t(\Theta) + \text{log} P(\Theta) + \mathcal{H}</script>

<p>So, after molding the equation, we have the</p>

<script type="math/tex; mode=display">\Theta^{t+1} = \text{argmax} [ Q^t(\Theta) + \text{log} P(\Theta) ].</script>

<p><br /></p>

<h4 id="final-algorithm">Final Algorithm</h4>

<p>Every iteration of the EM algorithm starts by finding a lower bound $B(\Theta,\Theta^t)$ at the current guess $\Theta^t$. Then, the lower bound is maximized to improved the estimate $\Theta^{t+1}$. Thus, the EM algorithm can be written compactly as,</p>

<ul>
  <li>Expectation –&gt; $f^t (N) = P( N | Y, \Theta^t) $</li>
  <li>Maximization –&gt; $ \Theta^{t+1} = \text{argmax} [Q^{t}(\Theta) + \text{log} P(\Theta)] $</li>
</ul>

<p>Finally, it is important to know that $Q^t(\Theta)$ is calculated in the expectation by using the current estimate of $\Theta$. However, the M-Step is optimizing $Q^{t}$ w.r.t. the free paramater $\Theta$ to generate a new estimate, $\Theta^{t+1}$.</p>

<p><br /></p>

<h4 id="additional-links-1">Additional Links</h4>

<ul>
  <li><a href="https://www.jstor.org/stable/2527783?seq=1#page_scan_tab_contents">The First Paper</a></li>
  <li><a href="http://web.mit.edu/6.435/www/Dempster77.pdf">Seminal Paper</a></li>
  <li><a href="http://www.cs.toronto.edu/~fritz/absps/emk.pdf">Lower Bound Paper</a></li>
</ul>

<p><br /><br /></p>

<h1 id="model-selection----complexity-selection">Model Selection –&gt; Complexity Selection</h1>

<p>The main idea of this section was summed up by George Box when he said “essentially, all models are wrong, but some are useful.” I’m not going to go into much detail on this topic because we have already discussed most of the important topics in the Bias-Variance discussion. However, I will provide an example of model selection that I conducted a few months ago.</p>

<h3 id="model-selection-example">Model Selection Example</h3>

<p>Recently, there has been quite a bit of a discussion around GNSS spoofing. The primary concern is that the signal structure is public knowledge so anyone with the technical background could replicate the signal and broadcast is to a user. An example of a spoofed receiver is shown in the figure below.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/asxg5rvUFmB7i9RGtNVNePN1HEaWIGhG6jLIwQaKykC6_q2JFqt5RgKNIkl3WSE1dUiGqxbCF3p7lsYyEl1xo9SmvgTwAdRIF6FZlctkv3WWZ4i8zijv3JxmmgZkq_2Ynqbxs7NeP-oB1KyplfcInU-ZufwUvEW_BK19twcRFqVWyjeWHD28y5gobfKBnkYBPRSOriPK0EQ62ZNFsa-gHas6DxseZY94pcvbIIdtnfWaTUdyZpW35St_cpeb2PtadcFNlrAvYkVEkEWkVR2WgLfKHoSbj3Yr84kTi-Gdm73UhfzoOSYk42SXY38FvG2KuYzUbR2D0qst1DOmWyjBX9EuyLOSKQTrs8o7wKRPAqom1zM9XKppJDfU-MUf22SX9WVXSfWO3Poz0j5H9eSNY2BCbW1BVd_ZdLPofBekRatkI5gMGFstJQVW6vYDyIX4cSYr8lR8phAXtFzpi2Luxi-594Y1WFhU1_jr9ag1P9byVlYHd1W2h6JooR6wGfkpYHvOuxxKUgnmwuXcGAGy3j7yQM2ZkH5Qkc-mqD7b9mio1VWKWQ_XBTzYWoTIRZQhO2mxU6QB-eZP1pCjly2aB0u6dqZDa6sBvr5G7F2lN394wZyTulsvgAO0c3uGv_xdwMD9VO7jVZ8mop9XLlCR2PR-gMll_t8dQn9lbKlYhQDEXw=w1205-h665-no
" target="_blank"><img src="https://lh3.googleusercontent.com/asxg5rvUFmB7i9RGtNVNePN1HEaWIGhG6jLIwQaKykC6_q2JFqt5RgKNIkl3WSE1dUiGqxbCF3p7lsYyEl1xo9SmvgTwAdRIF6FZlctkv3WWZ4i8zijv3JxmmgZkq_2Ynqbxs7NeP-oB1KyplfcInU-ZufwUvEW_BK19twcRFqVWyjeWHD28y5gobfKBnkYBPRSOriPK0EQ62ZNFsa-gHas6DxseZY94pcvbIIdtnfWaTUdyZpW35St_cpeb2PtadcFNlrAvYkVEkEWkVR2WgLfKHoSbj3Yr84kTi-Gdm73UhfzoOSYk42SXY38FvG2KuYzUbR2D0qst1DOmWyjBX9EuyLOSKQTrs8o7wKRPAqom1zM9XKppJDfU-MUf22SX9WVXSfWO3Poz0j5H9eSNY2BCbW1BVd_ZdLPofBekRatkI5gMGFstJQVW6vYDyIX4cSYr8lR8phAXtFzpi2Luxi-594Y1WFhU1_jr9ag1P9byVlYHd1W2h6JooR6wGfkpYHvOuxxKUgnmwuXcGAGy3j7yQM2ZkH5Qkc-mqD7b9mio1VWKWQ_XBTzYWoTIRZQhO2mxU6QB-eZP1pCjly2aB0u6dqZDa6sBvr5G7F2lN394wZyTulsvgAO0c3uGv_xdwMD9VO7jVZ8mop9XLlCR2PR-gMll_t8dQn9lbKlYhQDEXw=w1205-h665-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 5 :: Spoofing Example
</p>
<p><br /></p>

<p>I wanted to see how hard it is to detect spoofing. To conduct this study, I was provided a very large dataset from UT Austin ( $\sim$ 2,000,000 labeled data points ). And I trained a few learning algorithms; however, it seemed like no matter how complex the algorithm I was stuck at a threshold of 99.6% classification accuracy. For example, below is a fairly complex binary classification tree.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/7J4Fkd2GtCwEDDf6AhPph0pVuic-gl72BCrBwpHCFHbd9WS7TPXnaLKLa7a9a8C3zxSDGCBxJntfgFx2LKDlQhGmgTq2r0fZorRSggEU_2IhpdLXOm8LLQYOlzFxeghQkSa46L6QpD_o8lSe_xAYj61DyHy0BHTFNHE5b8ViB5DaHdj_J6qMjGwWn_TgIusU2AKsw8or9jYRN-S-ckl7fwcCpMgjrjnADB88HwXzobWWEzGn7niZBjVlaxP0m4NYJNEk8oEXTS78PlU55UwYcz8FaYql7gfJ4bzGNby9U4Pw1DwVObr4Bmva7uurQqoTifnC1CavZjDfnDDpnSr-QlD-10LmYrEg1jg0wdrtIkY16-1Li2fFUj9K0QUIx_qUD66hvy_M3OW8hqEqeAp7xigAqanNRLlmCkcquCCelGOWUcsOvAIrI9gt_wdO6wcNNttb_MgeNs1JKoi7XGyjA3O1TNkEUjK55exrpCnA12q5qlySdUtaXYm7Y1qAuFDeH7tuCLofM3Tu0gFTV3QBkDzXBpIUk85zbEtlr3iESG7SnhEHPDy5vLAFqIG51TRSlgPE_mVyiF5pk_REZLX-QaoVhUEYccUVoZ0LsR0HqFuxIAV87gQZwrhsy2I2nk_43gi8XO2opJ25wB1podxBrpd2gmjKogkTi1ThX9d1DJSCNw=w1280-h626-no
" target="_blank"><img src="https://lh3.googleusercontent.com/7J4Fkd2GtCwEDDf6AhPph0pVuic-gl72BCrBwpHCFHbd9WS7TPXnaLKLa7a9a8C3zxSDGCBxJntfgFx2LKDlQhGmgTq2r0fZorRSggEU_2IhpdLXOm8LLQYOlzFxeghQkSa46L6QpD_o8lSe_xAYj61DyHy0BHTFNHE5b8ViB5DaHdj_J6qMjGwWn_TgIusU2AKsw8or9jYRN-S-ckl7fwcCpMgjrjnADB88HwXzobWWEzGn7niZBjVlaxP0m4NYJNEk8oEXTS78PlU55UwYcz8FaYql7gfJ4bzGNby9U4Pw1DwVObr4Bmva7uurQqoTifnC1CavZjDfnDDpnSr-QlD-10LmYrEg1jg0wdrtIkY16-1Li2fFUj9K0QUIx_qUD66hvy_M3OW8hqEqeAp7xigAqanNRLlmCkcquCCelGOWUcsOvAIrI9gt_wdO6wcNNttb_MgeNs1JKoi7XGyjA3O1TNkEUjK55exrpCnA12q5qlySdUtaXYm7Y1qAuFDeH7tuCLofM3Tu0gFTV3QBkDzXBpIUk85zbEtlr3iESG7SnhEHPDy5vLAFqIG51TRSlgPE_mVyiF5pk_REZLX-QaoVhUEYccUVoZ0LsR0HqFuxIAV87gQZwrhsy2I2nk_43gi8XO2opJ25wB1podxBrpd2gmjKogkTi1ThX9d1DJSCNw=w1280-h626-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 6 :: Decision Tree
</p>

<p>So, I turned my attention to trying to minimize the complexity of the system while mainting the integrity of the classifier. To do this, I used a simple ensemble of trees, where the key concept is that many weak learners can be aggregated into one
high-fidelity estimator.</p>

<p>To reduce the complexity, we first looked at the number of trees required in our ensemble. To measure the accuracy of our tree ensemble, we looked at the out of bag (oob) error.  That is, each tree is trained on a subset of data ( i.e., a bag ) and tested on the remaining data. The oob error as a function of the number of trees in an ensemble is shown below.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/C67uCmkeKOSBIN48GHpnrKn3bIn5GoC9AvohV1Nw_4hImY3R3veqks2vU3t_JRsHn1dY9I2DT5h9v6-VsJJORh9Ti7Z1s5mnTNAhZSegbiK2fnroaHUY-wOdjL0PLizQAnnlfuD2D8AL01o8qvWxr3I1DT58dycQUbgMv99saWfMvkvSlw-iBl7J22z_wHORxUfs8AKN0M5417kW-vjzM9xjs70XQG51IfrH65VjK__VWhC4aUsf1r9t7DeYhe52BN1goeBTkx-DV2js0H48LNdP0MYk2VXsFggaodqF99rlViYrXjMbBm3QnmelINao0Vo1Ib21viUJaHjbBro9zDWJSIP1mz3XY3pAiNxBJNBTznZoOSIXdvtNbHICjng7oueFriOzn_nv2R_XLDTDCsKS4HDmNt0tMgbyVs86lZH_xcS5GsiFm-i_NXDAVoMDaGigakOFEnedUqtSsfWhlBMT_NSoFG2Y-iCWO13RS8mnR9k4KTG-1ppuiFUZ7Wcnf-lL73YYD-rfa0JsTQSi8fbnEJCDfA4BGAokqXIVXyeTkFDZcx5Piid47xSZtq-TrccmgelChgAyOzDUkIpkOsRWwoKeWcA0p_MLHsEHF9qaQQWlkVqWsMXyKVd-IVSXbGECaF3xpFTGmA5OcSzg5cqP8YfaZecFq-LmyRRiq88B1Q=w1280-h597-no
" target="_blank"><img src="https://lh3.googleusercontent.com/C67uCmkeKOSBIN48GHpnrKn3bIn5GoC9AvohV1Nw_4hImY3R3veqks2vU3t_JRsHn1dY9I2DT5h9v6-VsJJORh9Ti7Z1s5mnTNAhZSegbiK2fnroaHUY-wOdjL0PLizQAnnlfuD2D8AL01o8qvWxr3I1DT58dycQUbgMv99saWfMvkvSlw-iBl7J22z_wHORxUfs8AKN0M5417kW-vjzM9xjs70XQG51IfrH65VjK__VWhC4aUsf1r9t7DeYhe52BN1goeBTkx-DV2js0H48LNdP0MYk2VXsFggaodqF99rlViYrXjMbBm3QnmelINao0Vo1Ib21viUJaHjbBro9zDWJSIP1mz3XY3pAiNxBJNBTznZoOSIXdvtNbHICjng7oueFriOzn_nv2R_XLDTDCsKS4HDmNt0tMgbyVs86lZH_xcS5GsiFm-i_NXDAVoMDaGigakOFEnedUqtSsfWhlBMT_NSoFG2Y-iCWO13RS8mnR9k4KTG-1ppuiFUZ7Wcnf-lL73YYD-rfa0JsTQSi8fbnEJCDfA4BGAokqXIVXyeTkFDZcx5Piid47xSZtq-TrccmgelChgAyOzDUkIpkOsRWwoKeWcA0p_MLHsEHF9qaQQWlkVqWsMXyKVd-IVSXbGECaF3xpFTGmA5OcSzg5cqP8YfaZecFq-LmyRRiq88B1Q=w1280-h597-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 7 :: Number of Required Trees
</p>
<p><br /></p>

<p>Next, we looked again at the obb error but this the we wanted to minimize the splits in a tree. For this, it can be seen in the image below that the error hits a minimum at roughly 25 splits.</p>

<p align="center">
<a href="https://lh3.googleusercontent.com/RuGgy4xTlEBkVWP0d8Wjz3rh4P4rn99upH0w_pw8_xKF0-IfvXh4uM5YuOu1_3uYkXT_Grkhmp5CnduhngmPG_RCGg-qhikMUny5Zk9AQbTR7F2Iy_wfWunfl5lmLHHjnghqwMc89GmDnjelfFjFIgbbfreH11WRjy3SxtfSDpKncuXscoS2mLgqaYWfNxvVfSHI72CjXJmer-KKncVYSlnbgVIfukGFP18Loos5FlmV3r6ariHnQ3swRg9Ev6oZFpK3N-YYX_7MqJtW8fmrfQdRS2iuRsq3LbdsePSzYt73Z1fyEbiui_69IHltNRUclk_boKuogfQmXMEKf3qUbdN8wcgGhGSU4EkUWjDH3NynkFPJV_d5BdNzMDXtGU3W19PdMRgo6pXWobjNCn32y2nfrHJomAtVHyNsTbvA_HBeXe2eCwGWeQMsAC7cllr6ovHsLS8MN0UjEadDbZhBGxIWfx1cCW1bLVmriU3VmJXyUU84UdpKuzxWjiMtDQH0FR2MT7aclKtwPuYH8T9VVbXkV5WICF-rFzyWSVeERwlBTnhbvZKvu3VGm17fm3-SHpEMuLeLO68ljlqyxWXB6PyuN9uy3nMxdZvU65HkXMU8s4BOiYrj-ZEXE3gbkI2F5cGTih2cs8Sv_NQu8l61hv1lPt7wi9s7s6cj25F1apzojw=w1280-h597-no
" target="_blank"><img src="https://lh3.googleusercontent.com/RuGgy4xTlEBkVWP0d8Wjz3rh4P4rn99upH0w_pw8_xKF0-IfvXh4uM5YuOu1_3uYkXT_Grkhmp5CnduhngmPG_RCGg-qhikMUny5Zk9AQbTR7F2Iy_wfWunfl5lmLHHjnghqwMc89GmDnjelfFjFIgbbfreH11WRjy3SxtfSDpKncuXscoS2mLgqaYWfNxvVfSHI72CjXJmer-KKncVYSlnbgVIfukGFP18Loos5FlmV3r6ariHnQ3swRg9Ev6oZFpK3N-YYX_7MqJtW8fmrfQdRS2iuRsq3LbdsePSzYt73Z1fyEbiui_69IHltNRUclk_boKuogfQmXMEKf3qUbdN8wcgGhGSU4EkUWjDH3NynkFPJV_d5BdNzMDXtGU3W19PdMRgo6pXWobjNCn32y2nfrHJomAtVHyNsTbvA_HBeXe2eCwGWeQMsAC7cllr6ovHsLS8MN0UjEadDbZhBGxIWfx1cCW1bLVmriU3VmJXyUU84UdpKuzxWjiMtDQH0FR2MT7aclKtwPuYH8T9VVbXkV5WICF-rFzyWSVeERwlBTnhbvZKvu3VGm17fm3-SHpEMuLeLO68ljlqyxWXB6PyuN9uy3nMxdZvU65HkXMU8s4BOiYrj-ZEXE3gbkI2F5cGTih2cs8Sv_NQu8l61hv1lPt7wi9s7s6cj25F1apzojw=w1280-h597-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 8 :: Miniminum Number of Splits 
</p>

<p>So, a new learner was trained with 20 trees in the ensemble and a maximum of 25 splits in a single tree. The classification results for our simple ensemble are shown in Figure 9. As can be seen in the figure, the classification integrity of the learner was maintain as the complexity was decreased.</p>

<p><br /></p>

<p align="center">
<a href="https://lh3.googleusercontent.com/cPWQdP3ygy-aTUiw2FKWLFzIdlxXh6aP9wRFoIZm5hWYTeLi-EFuqd0HIVjve0WwcxypxoF0ARiUepF0K_Jn5zvSG04z6yt47K5V80A36HP7sZFBmWmg8M3TrbLquK_JvWP5n9Rg6927bI7TQD74J4vh5Kh6yFD8hE8LxFYM2HFo0BJJnPjPNateMM86nrtpx9zrLODY0FxfJ1WkFuFdi_y17TB8SsXiovJO6WwflSA7J8ZtX6zJUCCHBMvhUfh-d4w1zNW9dkZVN2HFblzCDhQNbR2NCLyUKW2_NUDQYR39IbVYZLAE-QxNns87jUy6Iu91xh1l3s6Pva_GlSOSIvC7fF7Fs1F3zj8CLNnx2KaaebKOz6RsN9y8JYHwVQAuCG_N13ya_oXTDrdNWMaa_OKEPyjXOXw3I8uo_z4DkP_IJoQ3Qm1dk7erkLYdXr4cCdNuThpDi8mcvYhbbk6pprSwY8lU_82qD6Kit3-qw7B71Udqec1rTcJStfYaIdMn7xCJyGwlbNzHZ1OlMPcFkF_GT4LTgJs960U52u3JL5x9PEeRbA2n8ly2-c-fgBFAKUUjRMkP31Yc8BCD_EDFaNG162ZlW2p7ySvsPKfC8GvyvEmIUI0HEv39qgqcwDLFFEa9Viigtb21Rbj7gU6ex0wqZUHwd6UAVGWTVf8SucVvOQ=w1280-h597-no
" target="_blank"><img src="https://lh3.googleusercontent.com/cPWQdP3ygy-aTUiw2FKWLFzIdlxXh6aP9wRFoIZm5hWYTeLi-EFuqd0HIVjve0WwcxypxoF0ARiUepF0K_Jn5zvSG04z6yt47K5V80A36HP7sZFBmWmg8M3TrbLquK_JvWP5n9Rg6927bI7TQD74J4vh5Kh6yFD8hE8LxFYM2HFo0BJJnPjPNateMM86nrtpx9zrLODY0FxfJ1WkFuFdi_y17TB8SsXiovJO6WwflSA7J8ZtX6zJUCCHBMvhUfh-d4w1zNW9dkZVN2HFblzCDhQNbR2NCLyUKW2_NUDQYR39IbVYZLAE-QxNns87jUy6Iu91xh1l3s6Pva_GlSOSIvC7fF7Fs1F3zj8CLNnx2KaaebKOz6RsN9y8JYHwVQAuCG_N13ya_oXTDrdNWMaa_OKEPyjXOXw3I8uo_z4DkP_IJoQ3Qm1dk7erkLYdXr4cCdNuThpDi8mcvYhbbk6pprSwY8lU_82qD6Kit3-qw7B71Udqec1rTcJStfYaIdMn7xCJyGwlbNzHZ1OlMPcFkF_GT4LTgJs960U52u3JL5x9PEeRbA2n8ly2-c-fgBFAKUUjRMkP31Yc8BCD_EDFaNG162ZlW2p7ySvsPKfC8GvyvEmIUI0HEv39qgqcwDLFFEa9Viigtb21Rbj7gU6ex0wqZUHwd6UAVGWTVf8SucVvOQ=w1280-h597-no
" border="0" alt=" photo inifModel_zpszslpm6g2.png" /></a>
</p>
<p align="center">
Fig 9 :: Confusion Matrix for Ensemble 
</p>
<p><br /></p>

<p><br /></p>

<h4 id="additional-links-2">Additional Links</h4>

<ul>
  <li><a href="https://www.youtube.com/watch?v=gajUDdlBX3w">Video Overview</a></li>
  <li><a href="https://www.cs.cmu.edu/afs/cs/academic/class/10601-f10/lecture/lec16.pdf">Good Slides</a></li>
</ul>

<p><br /><br /></p>

